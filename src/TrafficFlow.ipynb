{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TFG Alberto Pampín\n",
    "\n",
    "## Descripción del dataset\n",
    "\n",
    "En primer lugar hay que realizar los imports necesarios:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se realiza la carga del fichero .csv que contiene los datos:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#csv_path = '../data/2_Oct2019.csv'\n",
    "csv_path = '../data/historico_10_19_02_20.csv'\n",
    "df = pd.read_csv(csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En este fichero se encuentran las mediciones que han realizado los sensores instalados en la ciudad de Santiago\n",
    "de Compostela desde Octubre-2019 hasta Febrero-2020 (ambos incluidos).\n",
    "\n",
    "**NOTA**: Al tratarse de un problema real las mediciones realizadas a partir de Marzo-2020 se han visto afectadas por\n",
    "las restricciones sanitarias a causa del COVID-19, es por eso que no se tomarán en cuenta las mediciones a partir\n",
    "de dicha fecha.\n",
    "\n",
    "Ahora veamos cómo son los datos:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Las columnas del dataset son las siguientes:\n",
    "* `_id` (Integer): Identificador de la medición dentro del mes\n",
    "* `speed` (Integer): NA\n",
    "* `sensor` (String): Nombre del sensor que realizó la medición\n",
    "* `flow` (Integer): Su valor entre 12 muestra el número de vehículos que pasaron sobre el sensor en los últimos 5 minutos\n",
    "* `FID` (String): Identificador de la medición global -> PRIMARY KEY\n",
    "* `datetime` (Timestamp): Fecha y hora en la que se tomó la medición.\n",
    "Cada sensor inserta una nueva medición cada 5 minutos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hay un total de **2904410 mediciones** y **6 columnas**.\n",
    "\n",
    "Algunos datos interesantes sobre el dataset:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El max de `flow` y por ende el de `car_count` no parece un número muy normal, y menos\n",
    "tratándose de una ciudad como Santiago de Compostela, dónde es imposible que circulen 8333\n",
    "vehículos sobre un sensor en 5 minutos:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.boxplot(column=['flow'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_flow = df.loc[df['flow'] == 99999]\n",
    "len(bad_flow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hay 31 mediciones con un valor erróneo para la columna `flow`: **Es necesario arreglar estos valores extremos!**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Procesamiento del dataset\n",
    "\n",
    "Algunos de los datos del dataset no interesan, bien porque su valor no es válido (`speed`) o bien porque\n",
    "son simples identificadores (`_id` y `FID`). También se deberán formatear otras columnas:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.pop('speed')\n",
    "df.pop('FID')\n",
    "df.pop('_id')\n",
    "\n",
    "df.loc[:,'datetime'] = pd.to_datetime(df.loc[:,'datetime'], format='%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "df['car_count'] = df.loc[:, 'flow'] // 12\n",
    "\n",
    "# Ordena por fecha.\n",
    "# ignore_index=True -> Pone los index del 0 al n-1 (todos por orden)\n",
    "# inplace = True -> Para que ya lo haga sobre el df en vez de devolver el df ordenado\n",
    "df.sort_values(by='datetime', ignore_index=True, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Acciones realizadas:\n",
    "1. La columna `speed` no aporta nada, todos su valores son -9999\n",
    "2. La columna `FID` tampoco, es un identificador de cada medición, al igual que `_id`\n",
    "3. La columna `datetime` tuvo que ser formateada para obtener un formato válido\n",
    "4. La columna `flow` es útil, pero es más interesante conocer el número de vehículos que\n",
    " pasaron sobre el sensor en los últimos 5 minutos: `car_count`\n",
    "5. Se han ordenado todas las entradas por el campo `datetime`\n",
    "\n",
    "Seleccionemos 5 mediciones al azar:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.sample(n=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos algunas estadísticas del conjunto de datos:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como ya se comentó en la sección anterior, existen 31 outlayers claros ( valor 99999.0 en la columna `flow`) que deben\n",
    "ser eliminados:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[df['flow'] != 99999.0]\n",
    "df = df[df['car_count'] != 8333.25]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos ver que ya no hay ninguna fila con `flow == 99999.0`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_flow = df.loc[df['flow'] == 99999.0]\n",
    "len(bad_flow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Revisando de nuevo las estadísticas del dataset:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe().transpose()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.boxplot(column=['flow'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A simple vista no se ven outlayers tan claros como anteriormente. Debido a que `flow` solo resulta de interés para\n",
    "calcular `car_count`, esta característica puede ser eliminada ya del dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.pop('flow')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experimentos planteados\n",
    "\n",
    "Los experimentos a realizar consisten en predecir el tráfico en el punto en el que se ubica el\n",
    "sensor `PM072` (CITIUS) en un instante `t` a partir de las mediciones realizadas por otros\n",
    "sensores en un instante `t-x`. Los experimentos contemplados son los siguientes:\n",
    "\n",
    "1. Predecir en `PM072` a partir de:\n",
    "    - `PM029` (Entrada túnel Romero Donallo)\n",
    "    - **No es posible, ya que ese sensor estaba averiado** - `PM034`(Rotonda Camiño Novo - Avda. Mestre Mateo)\n",
    "\n",
    "2. Predecir en `PM072` a partir de:\n",
    "    - `PM024` (Rotonda Camiño Novo - Avda. Romero Donallo)\n",
    "    - `PM030` (Avda. Rosalía de Castro - Rotonda Camiño Novo)\n",
    "    - `PM031` (Avda. Romero Donallo - Rotonda Camiño Novo)\n",
    "    - `PM032` (Avda. Rosalía de Castro - Rotonda Camiño Novo)\n",
    "    - **No es posible, ya que ese sensor estaba averiado** -`PM033` (Avda. Mestre Mateo - Rotonda Camiño Novo)\n",
    "\n",
    "3. Predecir en `PM072` a partir de:\n",
    "    - `PM020` (Rotonda Galuresa - Avda. Romero Donallo)\n",
    "    - `PM076` (Rúa do Horreo - Rotonda Galuresa)\n",
    "    - `PM077` (Avda. Romero Donallo - Rotonda Galuresa)\n",
    "    - `PM079` (Rúa do Horreo - Rotonda Galuresa)\n",
    "\n",
    "4. Predecir en `PM072` a partir de:\n",
    "    - Todos los sensores disponibles\n",
    "\n",
    "Para cada uno de los experimentos anteriormente citados se llevará a cabo la implementación del modelo con:\n",
    "* Perceptrón multicapa\n",
    "* Red Neuronal Convolucional (CNN)\n",
    "* Red Neuronal Recurrente (RNN)\n",
    "\n",
    "Asimismo, se deberá realizar un análisis de la varianza y bias para cada experimento\n",
    "(Ver 6 primeras semanas Machine Learning Stanford: https://www.coursera.org/learn/machine-learning)\n",
    "\n",
    "Por otra parte, también se probarán diversas formas de incluir las marcas temporales (timestamps) en el modelo:\n",
    "* Día de la semana (1-7) y hora del día (minutos)\n",
    "* Día de la semana y hora del día *modelado con sin y cos*\n",
    "* Ventanas temporales (¿?)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experimento #1\n",
    "\n",
    "Tal y como se indicó en el apartado `Experimentos`, en el **Experimento #1** se tratará de predecir\n",
    "el tráfico en el punto en el que se ubica el sensor `PM072` (CITIUS) en un instante `t` a partir de\n",
    "las mediciones realizadas en un instante `t-x` por los sensores:\n",
    "* `PM029` (Entrada túnel Romero Donallo)\n",
    "* **No es posible, ya que es sensor estaba averiado** - `PM034`(Rotonda Camiño Novo - Avda. Mestre Mateo)\n",
    "\n",
    "\n",
    "### Análisis dataset Experimento #1\n",
    "`\n",
    "En primer lugar, hay que obtener solo aquellas mediciones que hayan sido tomadas por los sensores que resultan\n",
    "de interés para el experimento:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sensors_list = ['PM029', 'PM072']\n",
    "df_1 = df.loc[df['sensor'].isin(sensors_list)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Al igual que antes, veamos algunas estadísticas sobre este conjunto:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1.describe().transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos un boxplot:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1.boxplot(column=['car_count'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No parece haber un outlayer muy claro como en el apartado `Descripción del dataset`. Hay que tener en cuenta que los datos\n",
    "que se encuentran fuera de la caja o de los brazos de la misma, no pueden ser considerados outlayers automáticamente.\n",
    "Al tratarse de mediciones de tráfico, es evidente que a ciertas horas del día (principalmente de madrugada), el número de\n",
    "coches registrado suele ser muy bajo incluso 0, por lo que la media y los cuartiles se encuentran afectados por estas\n",
    "medicones."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Análisis gráfico Experimento #1\n",
    "\n",
    "Para ver la evolución de los datos del tráfico de manera más intuitiva se realizarán una serie de representaciones\n",
    "gráficas.\n",
    "\n",
    "La siguiente función recibe un dataframe, una lista de días y el nombre de un sensor. Grafica todas las mediciones\n",
    "realizadas por ese sensor (agregados de 5 minutos) a lo largo de los días indicados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_sensors_daily_data(df_orig, days_list, sensor):\n",
    "\n",
    "    # Solo selecciono la información de ese sensor en el rango indicado\n",
    "    df = df_orig.loc[(df_orig['sensor'] == sensor)\n",
    "                     & (df_orig['datetime'] >= days_list[0])\n",
    "                     & (df_orig['datetime'] <= days_list[-1]+datetime.timedelta(days=1))]\n",
    "\n",
    "    fig, axs = plt.subplots(days_list.shape[0], figsize=(15,15))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    fig.suptitle('Data Sensor ' + sensor, fontsize=16)\n",
    "\n",
    "    for i in range(days_list.shape[0]):\n",
    "        x = df.loc[(df['datetime'] >= days_list[i]) & (df['datetime'] <= days_list[i]+datetime.timedelta(days=1)), 'datetime']\n",
    "        y = df.loc[(df['datetime'] >= days_list[i]) & (df['datetime'] <= days_list[i]+datetime.timedelta(days=1)), 'car_count']\n",
    "\n",
    "        myFmt = mdates.DateFormatter('%H:%M')\n",
    "        axs[i].xaxis.set_major_formatter(myFmt)\n",
    "        axs[i].set(xlabel='Hours', ylabel='Car count')\n",
    "        axs[i].set_title('Day: '+ days_list[i].strftime(\"%Y-%m-%d (%A)\"))\n",
    "\n",
    "        axs[i].plot(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos probar a pasarle los 7 días de una semana para ver como evoluciona el tráfico que pasa\n",
    "por ese sensor durante esa semana:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "days = pd.date_range(start='2019-10-07', end='2019-10-13', freq='D')\n",
    "plot_sensors_daily_data(df_orig=df_1, days_list = days, sensor='PM072')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "También podemos graficar los lunes (o cualquier día de la semana: W-SUN, W-FRI) que hubo en un mes:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "days = pd.date_range(start='2019-10-01', end='2019-10-31', freq='W-MON')\n",
    "plot_sensors_daily_data(df_orig=df_1, days_list = days, sensor='PM072')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Las gráficas anteriores tienen mucho ruido, aunque resultan útiles para hacer una comprobación de outlayers.\n",
    "Sin embargo, para ver de una manera más directa si existe periodicidad en el tráfico es más interesante **representar\n",
    "los datos con agregados superiores a 5 minutos**\n",
    "\n",
    "La siguiente función recibe un dataframe, una lista de días, un valor `n` que indica el número de mediciones agregadas,\n",
    "y el nombre de un sensor. Grafica la media (mean) y desviación típica (std) de las mediciones realizadas durante el sensor\n",
    "durante esos días en **agregados de 5*n minutos**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_sensors_agregated_daily_data(df_orig, days_list, n, sensor):\n",
    "\n",
    "    # Solo selecciono la información de ese sensor en el rango indicado\n",
    "    df = df_orig.loc[(df_orig['sensor'] == sensor)\n",
    "                     & (df_orig['datetime'] >= days_list[0])\n",
    "                     & (df_orig['datetime'] <= days_list[-1]+datetime.timedelta(days=1))]\n",
    "\n",
    "    # Dataframe con los agregados\n",
    "    df_mean = pd.DataFrame(columns=df.columns)\n",
    "    df_std = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    for g, df_slice in df.groupby(np.arange(len(df)) // n):\n",
    "        mean_row = {'sensor': sensor, 'datetime': df_slice['datetime'].max(), 'car_count': df_slice['car_count'].mean()}\n",
    "        df_mean = df_mean.append(mean_row, ignore_index=True)\n",
    "\n",
    "        std_row = {'sensor': sensor, 'datetime': df_slice['datetime'].max(), 'car_count': df_slice['car_count'].std()}\n",
    "        df_std = df_std.append(std_row, ignore_index=True)\n",
    "\n",
    "    fig, axs = plt.subplots(days_list.shape[0], figsize=(15,15))\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    fig.suptitle('Data Sensor ' + sensor, fontsize=16)\n",
    "\n",
    "    for i in range(days_list.shape[0]):\n",
    "        x = df_mean.loc[(df_mean['datetime'] >= days_list[i]) & (df_mean['datetime'] <= days_list[i]+datetime.timedelta(days=1)), 'datetime']\n",
    "        y_mean = df_mean.loc[(df_mean['datetime'] >= days_list[i]) & (df_mean['datetime'] <= days_list[i]+datetime.timedelta(days=1)), 'car_count']\n",
    "        y_std = df_std.loc[(df_std['datetime'] >= days_list[i]) & (df_std['datetime'] <= days_list[i]+datetime.timedelta(days=1)), 'car_count']\n",
    "\n",
    "        myFmt = mdates.DateFormatter('%H:%M')\n",
    "        axs[i].xaxis.set_major_formatter(myFmt)\n",
    "        axs[i].set(xlabel='Hours', ylabel='Car count')\n",
    "        axs[i].set_title('Day: '+ days_list[i].strftime(\"%Y-%m-%d (%A)\"))\n",
    "\n",
    "        axs[i].plot(x, y_mean, label='mean')\n",
    "        axs[i].plot(x, y_std, label='std')\n",
    "        axs[i].legend(loc='upper left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos la evolución del tráfico (media y desviación típica) durante una semana con agregados de 30 minutos (5*6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "days = pd.date_range(start='2019-10-07', end='2019-10-13', freq='D')\n",
    "plot_sensors_agregated_daily_data(df_orig=df_1, days_list = days, n=6, sensor='PM072')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos la evolución del tráfico durante los lunes de un mes con agregados de 30 minutos (5*6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "days = pd.date_range(start='2019-10-01', end='2019-10-31', freq='W-MON')\n",
    "plot_sensors_agregated_daily_data(df_orig=df_1, days_list = days, n=6, sensor='PM072')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparación dataset Experimento #1\n",
    "\n",
    "#### Label PM072\n",
    "\n",
    "El objetivo del Experimento #1 es predecir el tráfico en el punto en el que se ubica el sensor `PM072` (CITIUS)\n",
    "en un instante `t` a partir de las mediciones realizadas en un instante `t-x` por el sensor `PM029`.\n",
    "\n",
    "A cualquier modelo es necesario pasarle un vector de características con el que pueda trabajar. En este caso, el vector\n",
    "de características tiene la siguiente forma:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "column_names = ['datetime', 'car_count_PM029', 'label_PM072']\n",
    "pd.DataFrame(columns = column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Es decir, para cada instante temporal (`datetime`) que hay en el dataset, debe haber un vector de características que\n",
    "contenga dicho instante temporal y el valor medido por los sensores que se usarán para predecir. Asimismo, también debe\n",
    "contener el valor medido por el sensor `PM072` `x minutos` después.\n",
    "\n",
    "Los sensores pueden fallar o detenerse por labores de mantenimiento, por lo que es posible que en algún instante temporal\n",
    "uno de los sensores tome una medición y otro no, quedando así el vector de características incompleto. Esto no puede\n",
    "permitirse, por lo que **si falta una medición de un sensor para un determinado instante temporal, todas las mediciones\n",
    "correspondientes a dicho instante deben ser eliminadas.**\n",
    "\n",
    "Para facilitar la preparación del dataset se ha creado la siguiente función. Recibe el dataset original, la lista de sensores\n",
    "que se usarán para predecir, el sensor en el que se quiere predecir y los `x minutos` de desfase temporal.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_df(df_orig, sensors_list, label_sensor, x):\n",
    "\n",
    "    # Instante temporal y car_count de dicho sensor\n",
    "    prepared_df = df_orig.loc[ df_orig['sensor'] == sensors_list[0] , ['datetime', 'car_count']]\n",
    "    # Renombrar la columna car_count\n",
    "    prepared_df.rename(columns={'car_count': 'car_count_' + sensors_list[0]}, inplace=True)\n",
    "\n",
    "    # MERGE no tiene en cuenta los index. Los reinicia y los pone del 0 al n-1 (todos en orden)\n",
    "    # INNER JOIN con los datos de cada sensor de la lista (sin contar el primero),\n",
    "    # asi evito el problema de que falten mediciones de algunos sensores en un determinado instante temporal\n",
    "    for ss in sensors_list[1:]:\n",
    "        aux = df_orig.loc[ df_orig['sensor'] == ss, ['datetime', 'car_count']]\n",
    "        aux.rename(columns={'car_count': 'car_count_' + ss}, inplace=True)\n",
    "        prepared_df = pd.merge(prepared_df, aux, on='datetime', how='inner')\n",
    "\n",
    "    # Obtengo los datos del sensor a predecir x minutos despues\n",
    "    aux = df_orig.loc[ df_orig['sensor'] == label_sensor, ['datetime', 'car_count']]\n",
    "    # Resto los x minutos de para poder hacer el JOIN y MANTENIENDO EL CAR_COUNT que interesa\n",
    "    aux['datetime'] = aux['datetime'] - datetime.timedelta(minutes=x)\n",
    "    aux.rename(columns={'car_count': 'label_' + label_sensor}, inplace=True)\n",
    "    prepared_df = pd.merge(prepared_df, aux, on='datetime', how='inner')\n",
    "\n",
    "    return prepared_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuación, se utiliza la función para preparar el dataset para el Experimento #1:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sensors_list = ['PM029']\n",
    "df_1 = prepare_df(df_1, sensors_list, label_sensor='PM072', x = 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**El `df_1` está ordenado por fecha y los Index van del 0 al n-1 (todos en orden)**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tiempo\n",
    "\n",
    "Antes de construir un modelo es importante entender los datos con los que se trabaja y estar seguro que los datos\n",
    "que se le pasan al modelo está correctamente formateados.\n",
    "\n",
    "Observando ls gráficas anteriores se puede observar claramente que el tráfico tiene un comportamiento\n",
    "cíclico según la *hora del día* y del *día de la semana*. Es decir, el tráfico de cada lunes durante todas las horas\n",
    "del día es muy similar. A continuación se codificará este comportamiento:\n",
    "\n",
    "#### Horas del día\n",
    "\n",
    "Una de las formas más comunes para representar características cíclicas es mediante el uso de la función seno y la función\n",
    "coseno [REFERENCIA]. En primer lugar, es necesario recuperar las horas y minutos de las fechas y convertirlo en segundos (o en minutos):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "date_time = pd.to_timedelta(df_1['datetime'].dt.strftime('%H:%M:%S'))\n",
    "date_time_s = date_time.dt.total_seconds().astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El tiempo en segundos no resulta muy útil como input para el modelo. Está claro que la periodicidad del tráfico es diaria.\n",
    "\n",
    "Para convertir el tiempo en una señal usable se puede usar el seno y el coseno:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seconds_in_day = 24*60*60\n",
    "df_1['hour_sin'] = np.sin(date_time_s * (2 * np.pi / seconds_in_day))\n",
    "df_1['hour_cos'] = np.cos(date_time_s * (2 * np.pi / seconds_in_day))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "De esta manera se logra modelar las horas como en un reloj, las 00h y están a continuación de las 23h.\n",
    "\n",
    "La gráfica correspondiente al primer día del dataset es la siguiente ([:288] porque cada hora hay 12 mediciones * 24h = 288):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(df_1[ 'hour_sin'][:288], label = 'hour_sin')\n",
    "plt.plot(df_1['hour_cos'][:288], label = 'hour_cos')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('12*24 = 288 mediciones diarias')\n",
    "plt.title('Time of day signal')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si solamente se observa la función seno, al trazar una línea horizontal se cruza en dos puntos, por lo que sólo teniendo\n",
    "en cuenta esta característica, las 00:00h y las 12:00h son lo mismo. Para solucionar esto se toma en consideración el coseno, con ambas\n",
    "características ya es posible distinguir esas horas y todo codificado de manera cíclica.\n",
    "\n",
    "Una forma más intuitiva de ver lo que acabamos de hacer es representar ambas características como si se tratase un reloj:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1[:288].plot.scatter('hour_sin','hour_cos').set_aspect('equal');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Comentario personal:** Fíjate en las tablas a continuación que, evidentemente,\n",
    "hour_sin` y  `hour_cos` son iguales para 2019-10-01 00:00:00 y 2019-10-02 00:00:00.\n",
    "Como nos interesa que también se tenga en cuenta el día de la semana tenemos que hacer algo más!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1[:2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1[288:290]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Días de la semana\n",
    "\n",
    "Tal y como hemos visto en las gráficas durante el `Análisis gráfico`, el tráfico tiene una clara frecuencia semanal.\n",
    "Se puede ver cómo las gráficas de cada uno de los lunes (por ejemplo) son muy similares. Esto es algo que nos interesa\n",
    "que nuestro modelo conozca, por lo que tenemos que realizar un trabajo similar al que hemos realizado con las horas.\n",
    "*Los días de la semana también son cíclicos!*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wday = df_1['datetime'].dt.weekday\n",
    "days_in_week = 7 # dt.weekday asigna valores del 0 (Lunes) al 6 (Domingo)\n",
    "df_1['wday_sin'] = np.sin(wday * (2 * np.pi / days_in_week))\n",
    "df_1['wday_cos'] = np.cos(wday * (2 * np.pi / days_in_week))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nuevamente, en una representación circular, vemos los 7 días de la semana:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1.plot.scatter('wday_sin','wday_cos').set_aspect('equal');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Comentario personal:** Cada uno de los 7 puntos que vemos contiene 288 puntos (hay 288 mediciones cada día).\n",
    "En la siguiente tabla podemos ver como cada día de la semana (del 0 al 6) tiene un `wday_sin` y `wday_cos` diferente!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1[0:2000:288]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Características auxiliares/extra\n",
    "\n",
    "Durante la preparación se utilizaron/crearon columnas extra en el dataset que no aportarán nada a nuestro modelo.\n",
    "Estas deben ser eliminadas antes del entrenamiento.\n",
    "\n",
    "(Se mantienen para facilitar la graficación posterior)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dataset final para Experimento #1\n",
    "\n",
    "Finalmente el dataset contiene:\n",
    "1. `datetime`: Fecha y hora de la medición\n",
    "2. `car_count_PM029`: Número de coches que pasaron por el sensor en los últimos 5 minutos\n",
    "3. `label_PM072`: El dato a predecir\n",
    "4. `hour_sin` y `hour_cos`: Hora del día codificada\n",
    "5. `wday_sin` y `wday_cos`: Día de la semana codificado\n",
    "\n",
    "\n",
    "Para facilitar los siguientes experimentos se ha creado la función `encode_time_sin_cos`, que hará lo comentado anteriormente:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def encode_time_sin_cos(enc_df):\n",
    "\n",
    "    date_time = pd.to_timedelta(enc_df['datetime'].dt.strftime('%H:%M:%S'))\n",
    "    date_time_s = date_time.dt.total_seconds().astype(int)\n",
    "\n",
    "    seconds_in_day = 24*60*60\n",
    "    enc_df['hour_sin'] = np.sin(date_time_s * (2 * np.pi / seconds_in_day))\n",
    "    enc_df['hour_cos'] = np.cos(date_time_s * (2 * np.pi / seconds_in_day))\n",
    "\n",
    "    wday = enc_df['datetime'].dt.weekday\n",
    "    days_in_week = 7 # dt.weekday asigna valores del 0 (Lunes) al 6 (Domingo)\n",
    "    enc_df['wday_sin'] = np.sin(wday * (2 * np.pi / days_in_week))\n",
    "    enc_df['wday_cos'] = np.cos(wday * (2 * np.pi / days_in_week))\n",
    "\n",
    "    # Se mantiene para graficar más tarde, debe ser eliminado antes de entrenar\n",
    "    #enc_df.pop('datetime')\n",
    "\n",
    "    return enc_df\n",
    "\n",
    "def encode_time(enc_df):\n",
    "\n",
    "    enc_df['week_day'] = enc_df['datetime'].dt.weekday\n",
    "    enc_df['hour'] = enc_df['datetime'].dt.hour\n",
    "    enc_df['min'] = enc_df['datetime'].dt.minute\n",
    "\n",
    "    enc_df.pop('datetime')\n",
    "\n",
    "    return enc_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementación Perceptrón Multicapa (MLP)\n",
    "\n",
    "#### Definición Perceptrón Multicapa (MLP)\n",
    "\n",
    "Está en el fichero MLP_Metodología.txt y en la Memoria\n",
    "\n",
    "#### Implementación Perceptrón Multicapa (MLP)\n",
    "\n",
    "#### División del dataset\n",
    "\n",
    "Es necesario dividir el dataset en los conjuntos de:\n",
    "* Entrenamiento: `90%`\n",
    "* Validación: `10%` (Dentro del de Entrenamiento)\n",
    "* Test: `10%`\n",
    "\n",
    "**Para evitar problemas con la distribución de las mediciones es necesario hacer un `shuffle`\n",
    "(reordenamiento aleatorio del dataset) antes de dividirlo.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "df_1_shuffled=df_1.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = len(df_1)\n",
    "train_df_1 = df_1_shuffled[0:int(n*0.90)]\n",
    "test_df_1 = df_1_shuffled[int(n*0.90):]\n",
    "\n",
    "# Guardo las columnas del datetime para ambos conjuntos\n",
    "train_dates = train_df_1.pop('datetime')\n",
    "test_dates = test_df_1.pop('datetime')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Separación de las 'features' y 'labels'\n",
    "\n",
    "Debemos separar las características del dato a predecir (`label_PM072`) en ambos conjuntos:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels = train_df_1.pop('label_PM072')\n",
    "train_features = train_df_1\n",
    "\n",
    "test_labels = test_df_1.pop('label_PM072')\n",
    "test_features = test_df_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Normalización de los datos\n",
    "\n",
    "Normalizar los datos es un paso importante para lograr un buen modelo, ya que\n",
    "ayuda a que el descenso de gradiente pueda converger de manera más rápida.\n",
    "\n",
    "La normalización debe realizarse tras la `División del dataset` y **utilizando solamente los datos de conjunto\n",
    "de entrenamiento.** Esto de sebe a que el conjunto de test juega el papel de datos que aún no han sido vistos,\n",
    "usar información procedente de estos datos para la normalización de todo el conjunto daría lugar a un *sesgo*\n",
    "durante la evaluación del desempeño del modelo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Esto es ESTANDARIZACIÓN\n",
    "train_mean = train_features.mean()\n",
    "train_std = train_features.std()\n",
    "\n",
    "train_features = (train_features - train_mean) / train_std\n",
    "test_features = (test_features - train_mean) / train_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Entrenamiento\n",
    "\n",
    "Nótese que en la función `model.fit` se incluye la opción `validation_split=0.1`. De esta\n",
    "manera se usará un `1O%` **de los datos del conjunto de entrenamiento para validación.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 25 == 0: print('\\n')\n",
    "    print('.', end='')\n",
    "\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),\n",
    "        PrintDot()\n",
    "    ]\n",
    "\n",
    "def build_and_compile_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.Dense(256, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu', input_shape=(len(train_features.columns),) ),\n",
    "      layers.Dense(256, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(256, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "#kernel_regularizer=regularizers.l2(0.0001),\n",
    "#layers.Dropout(0.5),\n",
    "\n",
    "  model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['mae']\n",
    "  )\n",
    "\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_and_compile_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    verbose=0,\n",
    "    callbacks=get_callbacks(),\n",
    "    batch_size=32,\n",
    "    epochs=200\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([20, 70])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Se guardan las predicciones en un df\n",
    "predictions = pd.DataFrame(model.predict(test_features), columns = ['predictions'])\n",
    "\n",
    "# Evaluar el modelo para el conjunto de test\n",
    "loss, mae = model.evaluate(test_features, test_labels, verbose=2)\n",
    "print(\"Loss (MSE): \", loss)\n",
    "print(\"MAE: \", mae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tras haber realizado múltiples pruebas con las distintas arquitecturas e hiperparámetros, se ha llegado\n",
    "a un modelo *vencedor*.\n",
    "\n",
    "El MSE es una medida difícil de interpretar, ya que no está en las mismas unidades\n",
    "que el problema. Por otra parte, el MAE es más fácil de interpretar, ya que este sí está en las mismas unidades.\n",
    "Sin embargo, **este valor no es representativo.**\n",
    "\n",
    "Tal y como se pudo observar en las gráficas del comienzo del trabajo,\n",
    "hay determinadas horas del día en las que el número de coches es más bajo o más alto. Por ejemplo, entre las 00:00\n",
    "y las 06:00 el número de coches es muy bajo, entre 5 y 10 (GENERALMENTE), mientras que en la franja de 06:00 a 18:00 \n",
    "varía entre 30 y 50.\n",
    "\n",
    "Decir que hay un error medio de 5 coches cuando pasan 60 coches es viable, no así si ese error se\n",
    "da cuando pasan tan solo 2.\n",
    "\n",
    "Para poder visualizar y comprender mejor la calidad del modelo se hará una representación gráfica a partir de los\n",
    "resultados obtenidos en las predicciones con el conjunto de test. La siguiente función muestra una gráfica para cada\n",
    "día de la semana en la que aparecen los datos reales y los predichos por el modelo.\n",
    "\n",
    "**NOTA:** Cada gráfica contiene los resultados de un determinado día de la semana (p.ej, Lunes), pero ese día de la semana\n",
    "puede corresponder a semanas/meses diferentes. Esto se hace para ver una representación más general, ya que no tendría\n",
    "sentido representar las predicciones de cada fecha exacta.\n",
    "\n",
    "El parámetro `freq` regula la cantidad de puntos que aparecen en cada gráfica. Se cojen puntos espaciados `freq` unidades.\n",
    "Con `freq=1` se representan todos los puntos; sin embargo, resulta complicado observar 500 puntos por gráfica."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def graph_predictions(test_dts, test_lbls, preds, freq):\n",
    "    # Como el conjunto de test es la parte final del conjunto general DESPUES DEL SHUFFLE,\n",
    "    # los indices empiezan en torno al 34 mil. Es mejor ponerlos a 0 para evitar problemas!\n",
    "    test_dts.reset_index(inplace=True, drop=True)\n",
    "    test_lbls.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Concateno las fechas, los labels y las predicciones en el mismo df\n",
    "    cc_df = pd.concat([test_dts, test_lbls], axis=1)\n",
    "    cc_df = pd.concat([cc_df, preds], axis=1)\n",
    "\n",
    "    # Obtengo solo la hora de cada fecha\n",
    "    cc_df['hour'] = cc_df['datetime'].dt.strftime('%H:%M')\n",
    "\n",
    "    # Obtengo el dia de la semana [0-Lunes, 6-Domingo]\n",
    "    cc_df['wday'] = cc_df['datetime'].dt.weekday\n",
    "\n",
    "    # Ordeno por 'wday' y luego por 'hour' -> No es necesario\n",
    "    cc_df.sort_values(by=['wday', 'hour'], ignore_index = True, inplace = True)\n",
    "\n",
    "    # Settings\n",
    "    fig, axs = plt.subplots(7)\n",
    "    fig.set_figheight(27.5)\n",
    "    fig.set_figwidth(15)\n",
    "    fig.tight_layout(pad=7.0)\n",
    "    fig.suptitle('Labels vs. Predictions', fontsize=16)\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "    # Gráfica para cada día de la semana\n",
    "    for i in range(7):\n",
    "\n",
    "        axs[i].xaxis.set_major_locator(plt.MaxNLocator(12))\n",
    "        axs[i].yaxis.set_major_locator(plt.MultipleLocator(10))\n",
    "        axs[i].set(xlabel='Hours', ylabel='Car count')\n",
    "        axs[i].set_title(day_names[i])\n",
    "\n",
    "        # DataFrame para cada día de la semana\n",
    "        aux = cc_df.loc[cc_df['wday'] == i]\n",
    "\n",
    "        # Lista de horas que hay en el DataFrame para el día especificado por i\n",
    "        x = aux['hour']\n",
    "\n",
    "        # Para una determinada hora puede haber varios label y predicciones (#label == #preds)\n",
    "        axs[i].scatter(x[::freq], aux['label_PM072'][::freq], label='Labels', s=10)\n",
    "        axs[i].scatter(x[::freq], aux['predictions'][::freq], label='Predictions', s=10)\n",
    "        axs[i].legend(loc='upper left')\n",
    "        axs[i].grid()\n",
    "\n",
    "    return cc_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_values = graph_predictions(test_dates, test_labels, predictions, freq = 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para comprobar algunos valores que puedan parecer atípicos se utiliza la siguiente linea:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_values.loc[ (check_values['wday'] == 6) & (check_values['hour'] > '06:00') & ((check_values['hour'] < '08:00')) ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementación MLP con Múltiples Timesteps\n",
    "\n",
    "Hasta ahora, en este `Experimento #1`, el entrenamiento para la predicción en el sensor `PM072` en el instante `t`\n",
    "se realizaba con la información procedente del sensor `PM029` en el instante `t-5minutos`.\n",
    "\n",
    "**Resulta interesante ver si la predicción se puede mejorar si se le proporciona a la red información de `10 y 15 minutos antes`**\n",
    "\n",
    "Ahora mismo el dataset del `Experimento #1` tiene la siguiente forma:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cada fila contiene la información temporal relevante, el valor medido por el sensor `PM029` en `t-5` y\n",
    "el valor medido por `PM072` en `t`.\n",
    "\n",
    "Ahora es necesario que cada vector de características contenga la medición realizada\n",
    "por `PM029` en:\n",
    "* `t-5`\n",
    "* `t-10`\n",
    "* `t-15`\n",
    "\n",
    "*Además de la información horaria para cada uno de esos timesteps*\n",
    "\n",
    "Para lograr este nuevo vector de características, en primer lugar se debe ordenar el dataset\n",
    "del `Experimento #1` por el campo `datetime` (Ya debería estar, puesto que se ordenó todo el\n",
    "dataset al principio y el loc de la función `prepare_df` los coge por orden y el merge resetea los index\n",
    "Además, el shuffle **NO** se ha hecho *inplace*)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1.sort_values(by='datetime', ignore_index=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como ya se ha visto durante el `Análisis de dataset`, el dataset **NO** contiene TODAS las mediciones realizadas\n",
    "durante los meses de Octubre a Febrero, por lo que no es posible coger las filas de 3 en 3.\n",
    "\n",
    "*(En caso de hacer esto, podría darse que un vector de características tenga información de mediciones\n",
    "realizadas 1 hora antes, 20 minutos antes y 5 minutos antes -> **NO SE PUEDE PERMITIR**)*\n",
    "\n",
    "Es necesario que el dataset SOLO contenga aquellas **mediciones para las que hay mediciones en los dos\n",
    "instantes temporales siguientes**.\n",
    "\n",
    "En primer lugar se realiza una copia de `df_1` y se extraen los labels y los timesteps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1_multi_timestep = df_1.copy(deep = True)\n",
    "dates = df_1_multi_timestep.pop('datetime')\n",
    "labels = df_1_multi_timestep.pop('label_PM072')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1_multi_timestep.tail(n=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ahora es necesario conocer para que timesteps existen los dos timesteps siguientes. Es decir, una medición 5 minutos\n",
    "después y 10 minutos después."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct_dates_index  = []\n",
    "for i in range(len(dates)-2):\n",
    "    if( (dates[i+1]-dates[i] == datetime.timedelta(minutes=5)) & (dates[i+2]-dates[i] == datetime.timedelta(minutes=10)) ):\n",
    "        correct_dates_index.append(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una vez obtenida la lista de los timesteps para los que sí hay dos mediciones consecutivas, se debe crear el vector de\n",
    "características anteriormente comentado."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aux_list = [], new_features = [], new_dates = [], new_labels = []\n",
    "for i in correct_dates_index:\n",
    "    v = df_1_multi_timestep.iloc[i:i+3].to_numpy() # Recupera 3 dilas\n",
    "    new_features.append(np.append(aux_list, v)) # Une las tres filas en un array y lo añade a una lista\n",
    "    new_dates.append(dates[i+2])\n",
    "    new_labels.append(labels[i+2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, para facilitar la visualización de los datos y las operaciones posteriores que se realizarán sobre los mismos,\n",
    "se ha creado un DataFrame. En este DataFrame se puede observar la fecha de la última medición de las 3 que hay en el vector\n",
    "de características y la medición realizada por `PM072 5 minutos depués`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1_multi_timestep = pd.DataFrame(new_features)\n",
    "df_1_multi_timestep.insert(loc=0, column='datetime', value = new_dates)\n",
    "df_1_multi_timestep.insert(loc=len(df_1_multi_timestep.columns), column='label_PM072', value = new_labels)\n",
    "\n",
    "df_1_multi_timestep"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para condensar el proceso anterior se ha creado la siguiente función. Esta función recibe el DataFrame utilizado en la\n",
    "`Implementación Perceptrón Multicapa (MLP) Simple` y devuelve el DataFrame necesario para `Implementación MLP con Múltiples Timesteps`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_multi_timestep_df(df_MLP):\n",
    "\n",
    "    df_MLP.sort_values(by='datetime', ignore_index=True, inplace=True)\n",
    "\n",
    "    df_multi_timestep = df_MLP.copy(deep = True)\n",
    "    dates = df_multi_timestep.pop('datetime')\n",
    "    labels = df_multi_timestep.pop('label_PM072')\n",
    "\n",
    "    correct_dates_index  = []\n",
    "    for i in range(len(dates)-2):\n",
    "        if( (dates[i+1]-dates[i] == datetime.timedelta(minutes=5)) & (dates[i+2]-dates[i] == datetime.timedelta(minutes=10)) ):\n",
    "            correct_dates_index.append(i)\n",
    "\n",
    "    aux_list = [], new_features = [], new_dates = [], new_labels = []\n",
    "    for i in correct_dates_index:\n",
    "        v = df_multi_timestep.iloc[i:i+3].to_numpy() # Recupera 3 filas\n",
    "        new_features.append(np.append(aux_list, v)) # Une las tres filas en un array y lo añade a una lista\n",
    "        new_dates.append(dates[i+2])\n",
    "        new_labels.append(labels[i+2])\n",
    "\n",
    "    df_multi_timestep = pd.DataFrame(new_features)\n",
    "    df_multi_timestep.insert(loc=0, column='datetime', value = new_dates)\n",
    "    df_multi_timestep.insert(loc=len(df_multi_timestep.columns), column='label_PM072', value = new_labels)\n",
    "\n",
    "    return df_multi_timestep"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### División, Separación y Normalización"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "df_1_mts_shuffled=df_1_multi_timestep.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = len(df_1_mts_shuffled)\n",
    "train_df_1_mts = df_1_mts_shuffled[0:int(n*0.90)]\n",
    "test_df_1_mts = df_1_mts_shuffled[int(n*0.90):]\n",
    "\n",
    "# Guardo las columnas del datetime para ambos conjuntos\n",
    "train_dates = train_df_1_mts.pop('datetime')\n",
    "test_dates = test_df_1_mts.pop('datetime')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels = train_df_1_mts.pop('label_PM072')\n",
    "train_features = train_df_1_mts\n",
    "\n",
    "test_labels = test_df_1_mts.pop('label_PM072')\n",
    "test_features = test_df_1_mts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Esto es ESTANDARIZACIÓN\n",
    "train_mean = train_features.mean()\n",
    "train_std = train_features.std()\n",
    "\n",
    "train_features = (train_features - train_mean) / train_std\n",
    "test_features = (test_features - train_mean) / train_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Entrenamiento\n",
    "\n",
    "Nótese que en la función `model.fit` se incluye la opción `validation_split=0.1`. De esta\n",
    "manera se usará un `1O%` **de los datos del conjunto de entrenamiento para validación.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 25 == 0: print('\\n')\n",
    "    print('.', end='')\n",
    "\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),\n",
    "        PrintDot()\n",
    "    ]\n",
    "\n",
    "def build_and_compile_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.Dense(256, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu', input_shape=(len(train_features.columns),) ),\n",
    "      layers.Dense(256, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(256, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "#kernel_regularizer=regularizers.l2(0.0001),\n",
    "#layers.Dropout(0.5),\n",
    "\n",
    "  model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        metrics=['mae']\n",
    "  )\n",
    "\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_and_compile_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    verbose=0,\n",
    "    callbacks=get_callbacks(),\n",
    "    batch_size=32,\n",
    "    epochs=200\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Se guardan las predicciones en un df\n",
    "predictions = pd.DataFrame(model.predict(test_features), columns = ['predictions'])\n",
    "\n",
    "# Evaluar el modelo para el conjunto de test\n",
    "loss, mae = model.evaluate(test_features, test_labels, verbose=2)\n",
    "print(\"Loss (MSE): \", loss)\n",
    "print(\"MAE: \", mae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementación RNN\n",
    "\n",
    "#### Definición RNN\n",
    "\n",
    "Está en el fichero Arquitecturas.txt y en la Memoria\n",
    "\n",
    "#### Implementación LSTM\n",
    "\n",
    "En esta sección se tratará la implementación del modelo con LSTM.\n",
    "\n",
    "Ahora mismo el dataset para el `Experimento #1` tiene las siguientes características:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1_rnn = df_1.copy(deep = True)\n",
    "df_1.sample()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tal y como se ha comentado en `Definición RNN`, este tipo de arquitectura es capaz\n",
    "de modelar el tiempo de forma explícita, por lo que ya *no es necesario* que se introduzca\n",
    "la información temporal:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_drop = ['wday_sin', 'wday_cos', 'hour_sin', 'hour_cos']\n",
    "df_1_rnn.drop(to_drop, axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por otra parte, para que la red pueda modelar el tiempo de manera correcta, es necesario\n",
    "que los datos que reciba estén ordenados temporalmente; es decir, por el campo `datetime`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1_rnn.sort_values(by=['datetime'], ignore_index = True , inplace = True)\n",
    "df_1_rnn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El modelo LSTM aprenderá una función que sea capaz de asociar una serie de secuencias pasadas (inputs) a una\n",
    "salida (output). Estas observaciones deben ser transformadas de tal manera que el modelo pueda aprender de ellas.\n",
    "\n",
    "Para poder hacer esto el modelo necesita suficiente contexto; es decir, cada ejemplo que reciba debe contener\n",
    "las mediciones realizadas en varios instantes temporales, pero siempre manteniendo el orden en el que estas\n",
    "han sido tomadas. En TensorFlow, una capa de tipo LSTM requiere una entrada con 3D la siguiente forma **[samples, timesteps, features]:**\n",
    "* *samples*: Número de ejemplos\n",
    "* *timesteps*: El número de instantes temporales que contiene cada ejemplo\n",
    "* *features*: El número de características del dataset\n",
    "\n",
    "**EN LA MEMORIA PONER UN DIBUJO DE COMO ES LA ENTRADA 3D**\n",
    "\n",
    "Se ha considerado que el **número de timesteps a usar será 3**. Es decir, cada ejemplo cuenta con la información tomada por\n",
    "los sensores a utilizar en cada Experimento en el instante `t-5, t-10 y t-15`. A partir de esta información, el modelo\n",
    "tratará de predecir el número de coches que pasarán por el sensor `PM072` en el instante `t`.\n",
    "\n",
    "Antes de crear esta entrada 3D es necesario normalizar y dividir el conjunto\n",
    "\n",
    "#### División del dataset, Separación y Normalización\n",
    "\n",
    "Cabe destacar que ahora, al utilizar una RNN (LSTM) NO se debe hacer el shuffle que\n",
    "se hizo previamente al trabajar con el MLP."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = len(df_1_rnn)\n",
    "train_df_1_rnn = df_1_rnn[0:int(n*0.90)]\n",
    "test_df_1_rnn = df_1_rnn[int(n*0.90):]\n",
    "\n",
    "# Guardo las columnas del datetime para ambos conjuntos\n",
    "train_dates = train_df_1_rnn.pop('datetime')\n",
    "test_dates = test_df_1_rnn.pop('datetime')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels = train_df_1_rnn.pop('label_PM072')\n",
    "train_features = train_df_1_rnn\n",
    "\n",
    "test_labels = test_df_1_rnn.pop('label_PM072')\n",
    "test_features = test_df_1_rnn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Esto es ESTANDARIZACIÓN\n",
    "train_mean = train_features.mean()\n",
    "train_std = train_features.std()\n",
    "\n",
    "train_features = (train_features - train_mean) / train_std\n",
    "test_features = (test_features - train_mean) / train_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Entrada celda LSTM\n",
    "\n",
    "Ahora que se ha realizado todo el proceso anterior, ya es posible crear la entrada 3D. Pero antes, se debe tener en cuenta que,\n",
    "al igual que se ha visto en la sección `Implementación MLP con Múltiples Timesteps`, el dataset no presenta TODAS las mediciones.\n",
    "\n",
    "El modelo debe recibir la información de los instantes `t-5, t-10 y t-15`. Para ello, es necesario seleccionar solo\n",
    "aquellas filas para las que hay dos mediciones en los dos instantes temporales posteriores. **Esas mediciones en esos\n",
    "3 instantes será la entrada 3D del modelo.**\n",
    "\n",
    "Asimismo, se deben almacenar solo los labels y fechas correspondientes a la medición en el instante `t-5`\n",
    "\n",
    "Para ello se ha creado la siguiente función, la cual recibe como parámetros todas las `features` y sus `labels`\n",
    "correspondientes. Devuelve la entrada LSTM en 3D, el`label` y `datetime` correspondiente a cada ejemplo de `3 timesteps`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_LSTM_data(input, output, dates):\n",
    "\n",
    "    # Necesario el reset para acceder por index\n",
    "    input.reset_index(inplace=True, drop=True)\n",
    "    output.reset_index(inplace=True, drop=True)\n",
    "    dates.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Mediciones para las que hay dos mediciones posteriores\n",
    "    correct_dates_index  = []\n",
    "    for i in range(len(dates)-2):\n",
    "        if( (dates[i+1]-dates[i] == datetime.timedelta(minutes=5)) & (dates[i+2]-dates[i] == datetime.timedelta(minutes=10)) ):\n",
    "            correct_dates_index.append(i)\n",
    "\n",
    "    Xs, ys, dts = [], [], []\n",
    "    for i in correct_dates_index:\n",
    "        v = input.iloc[i:i+3].to_numpy() # Recupera 3 filas\n",
    "        Xs.append(v)\n",
    "        ys.append(output[i+2])\n",
    "        dts.append(dates[i+2])\n",
    "\n",
    "    return np.array(Xs), np.array(ys), np.array(dts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_inputs, train_outputs, train_dates = create_LSTM_data(train_features, train_labels, train_dates)\n",
    "test_inputs, test_outputs, test_dates = create_LSTM_data(test_features, test_labels, test_dates)\n",
    "\n",
    "print('train_inputs.shape: ', train_inputs.shape)\n",
    "print('train_outputs.shape: ', train_outputs.shape)\n",
    "print('test_inputs.shape: ', test_inputs.shape)\n",
    "print('test_outputs.shape: ', test_outputs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como se puede observar, cada ejemplo tiene las mediciones correspondientes a `3 instantes temporales` y tiene\n",
    "asociada la medición realizada por el sensor `PM072` en el último instante temporal. **En realidad, el valor\n",
    "de la medición del sensor `PM072` de cada fila corresponde a la medición realiza 5 minutos después de las\n",
    "mediciones de los otros sensores de la fila!!. Esto ya se ha explicado al principio**\n",
    "\n",
    "Ahora que ya se ha obtenido una entrada y salida adecuadas, ya es posible comenzar con el entrenamiento.\n",
    "\n",
    "#### Entrenamiento"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 25 == 0: print('\\n')\n",
    "    print('.', end='')\n",
    "\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),\n",
    "        PrintDot()\n",
    "    ]\n",
    "\n",
    "def build_and_compile_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.LSTM(64,\n",
    "                   activation='relu', return_sequences=True,\n",
    "                   input_shape=(train_inputs.shape[1], train_inputs.shape[2]) ),\n",
    "      layers.LSTM(64, return_sequences=True,\n",
    "                   activation='relu'),\n",
    "      layers.LSTM(64,\n",
    "                   activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "#kernel_regularizer=regularizers.l2(0.0001),\n",
    "#layers.Dropout(0.5),\n",
    "\n",
    "  model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        metrics=['mae']\n",
    "  )\n",
    "\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_and_compile_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_inputs,\n",
    "    train_outputs,\n",
    "    validation_split=0.1,\n",
    "    verbose=0,\n",
    "    shuffle = False,\n",
    "    callbacks=get_callbacks(),\n",
    "    batch_size=32,\n",
    "    epochs=200\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([20, 70])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Se guardan las predicciones en un df\n",
    "predictions = pd.DataFrame(model.predict(test_inputs), columns = ['predictions'])\n",
    "\n",
    "# Evaluar el modelo para el conjunto de test\n",
    "loss, mae = model.evaluate(test_inputs, test_outputs, verbose=2)\n",
    "print('Loss (MSE): ', loss)\n",
    "print('MAE: ', mae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experimento #2\n",
    "\n",
    "Tal y como se indicó en el apartado `Experimentos`, en el **Experimento #2** se tratará de predecir\n",
    "el tráfico en el punto en el que se ubica el sensor `PM072` (CITIUS) en un instante `t` a partir de\n",
    "las mediciones realizadas en un instante `t-x` por los sensores:\n",
    "- `PM024` (Rotonda Camiño Novo - Avda. Romero Donallo)\n",
    "- `PM030` (Avda. Rosalía de Castro - Rotonda Camiño Novo)\n",
    "- `PM031` (Avda. Romero Donallo - Rotonda Camiño Novo)\n",
    "- `PM032` (Avda. Rosalía de Castro - Rotonda Camiño Novo)\n",
    "* **No es posible, ya que es sensor estaba averiado** - `PM033` (Avda. Mestre Mateo - Rotonda Camiño Novo)\n",
    "\n",
    "### Análisis dataset Experimento #2\n",
    "\n",
    "En primer lugar, hay que obtener solo aquellas mediciones que hayan sido tomadas por los sensores que resultan\n",
    "de interés para el experimento:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sensors_list = ['PM024', 'PM030', 'PM031', 'PM032', 'PM072']\n",
    "df_2 = df.loc[df['sensor'].isin(sensors_list)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Al igual que antes, veamos algunas estadísticas sobre este conjunto:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2.describe().transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos un boxplot:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2.boxplot(column=['car_count'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No parece haber un outlayer muy claro como en el apartado `Descripción del dataset`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Análisis gráfico Experimento #2\n",
    "\n",
    "Utilizando la función previamente creada se realizarán una serie de gráficas para ver la evolución de los datos del tráfico\n",
    "de manera más intuitiva.\n",
    "\n",
    "Para determinar si la medición en la que se registró el mayor valor para `car_count` es un outlayer se puede\n",
    "representar la evolución de ese día y de otros."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2.loc[df_2['car_count'] > 100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "days = pd.date_range(start='2019-12-12', end='2019-12-14', freq='D')\n",
    "plot_sensors_daily_data(df_orig=df_2, days_list = days, sensor='PM024')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En la gráfica correspondiente al `2019-12-17` se puede observar lo comentado en el anterior experimento. Los sensores\n",
    "pueden fallar (o no realizar mediciones por labores de mantenimiento), por lo que, en caso de que esto suceda, **las mediciones\n",
    "de los otros sensores que fueron realizados en ese mismo instante temporal deben ser descartadas.**\n",
    "\n",
    "*De esto ya se encarga la función que ha sido creada para preparar el dataset.*\n",
    "\n",
    "Por otra parte, la gráfica correspondiente `2019-12-18`, el día en el que se registró el máximo valor de `car_count`, se\n",
    "puede observar un pico muy pronunciado. Para tener más claro si se trata de un error en la medición se pueden observar las\n",
    "mediciones previas y posteriores a ese instante temporal para el sensor `PM032`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2.loc[(df_2['datetime'] >= '2019-12-18 10:30:00') & (df_2['datetime'] <= '2019-12-18 11:00:00') & (df_2['sensor'] == 'PM032')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Observando las mediciones anteriores y posteriores se puede observar que no hay entradas para los 10 minutos anteriores.\n",
    "**En ocasiones, los sensores se detienen o fallan y al recuperarse insertan como medición el total de coches que pasaron\n",
    "durante esos minutos que estuvieron fuera de servicio. Este valor es el resultado de un error, por lo que la medición debe\n",
    "ser eliminada:**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2 = df_2[df_2['car_count'] < 100.0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para determinar si alguna de las mediciones con mayor cuantía de vehículos (> 90) se trataba de un error se ha seguido un\n",
    "procedimiento similar. **Finalmente, se ha determinado que ninguna de esas mediciones se trata de un error.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparación dataset Experimento #2\n",
    "\n",
    "#### Label PM072\n",
    "\n",
    "Para este experimento, el vector de características que necesita el modelo tiene la siguiente forma:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "column_names = ['datetime', 'car_count_PM024', 'car_count_PM030', 'car_count_PM031', 'car_count_PM032', 'label_PM072']\n",
    "pd.DataFrame(columns = column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuación se utiliza la función para preparar el dataset para el Experimento #2:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sensors_list = ['PM024', 'PM030', 'PM031', 'PM032']\n",
    "df_2 = prepare_df(df_2, sensors_list, 'PM072', x = 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tiempo\n",
    "\n",
    "Para codificar el tiempo se usará la misma función que en el Experimento #1:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2 = encode_time_sin_cos(df_2)\n",
    "df_2.sample()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementación Perceptrón Multicapa (MLP)\n",
    "\n",
    "#### División del dataset, Separación y Normalización"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Shuffle\n",
    "df_2_shuffled=df_2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = len(df_2_shuffled)\n",
    "train_df_2 = df_2_shuffled[0:int(n*0.90)]\n",
    "test_df_2 = df_2_shuffled[int(n*0.90):]\n",
    "\n",
    "# Guardo las columnas del datetime para ambos conjuntos\n",
    "train_dates = train_df_2.pop('datetime')\n",
    "test_dates = test_df_2.pop('datetime')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels = train_df_2.pop('label_PM072')\n",
    "train_features = train_df_2\n",
    "\n",
    "test_labels = test_df_2.pop('label_PM072')\n",
    "test_features = test_df_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Esto es ESTANDARIZACIÓN\n",
    "train_mean = train_features.mean()\n",
    "train_std = train_features.std()\n",
    "\n",
    "train_features = (train_features - train_mean) / train_std\n",
    "test_features = (test_features - train_mean) / train_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Entrenamiento\n",
    "\n",
    "Nótese que en la función `model.fit` se incluye la opción `validation_split=0.1`. De esta\n",
    "manera se usará un `1O%` **de los datos del conjunto de entrenamiento para validación.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 25 == 0: print('\\n')\n",
    "    print('.', end='')\n",
    "\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),\n",
    "        PrintDot()\n",
    "    ]\n",
    "\n",
    "def build_and_compile_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.Dense(32, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu', input_shape=(len(train_features.columns),) ),\n",
    "      layers.Dense(64, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(32, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "#kernel_regularizer=regularizers.l2(0.0001),\n",
    "#layers.Dropout(0.5),\n",
    "\n",
    "\n",
    "  model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['mae']\n",
    "  )\n",
    "\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_and_compile_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    verbose=0,\n",
    "    callbacks=get_callbacks(),\n",
    "    batch_size=32,\n",
    "    epochs=200\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Se guardan las predicciones en un df\n",
    "predictions = pd.DataFrame(model.predict(test_features), columns = ['predictions'])\n",
    "\n",
    "# Evaluar el modelo para el conjunto de test\n",
    "loss, mae = model.evaluate(test_features, test_labels, verbose=2)\n",
    "mae"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_predictions(test_dates, test_labels, predictions, freq = 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementación MLP con Múltiples Timesteps\n",
    "\n",
    "Hasta ahora, en este `Experimento #2`, el entrenamiento para la predicción en el sensor `PM072` en el instante `t`\n",
    "se realizaba con la información procedente de los sensores `PM024, PM030, PM031 y PM032` en el instante `t-5minutos`.\n",
    "\n",
    "**Resulta interesante ver si la predicción se puede mejorar si se le proporciona a la red información de `10 y 15 minutos antes`**\n",
    "\n",
    "Ahora mismo el dataset del `Experimento #2` tiene la siguiente forma:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizando la función anteriormente definida se creará el DataFrama con la información necesaria para el Experimento:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2_multi_timestep = prepare_multi_timestep_df(df_2)\n",
    "df_2_multi_timestep"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### División, Separación y Normalización"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "df_2_mts_shuffled=df_2_multi_timestep.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = len(df_2_mts_shuffled)\n",
    "train_df_2_mts = df_2_mts_shuffled[0:int(n*0.90)]\n",
    "test_df_2_mts = df_2_mts_shuffled[int(n*0.90):]\n",
    "\n",
    "# Guardo las columnas del datetime para ambos conjuntos\n",
    "train_dates = train_df_2_mts.pop('datetime')\n",
    "test_dates = test_df_2_mts.pop('datetime')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels = train_df_2_mts.pop('label_PM072')\n",
    "train_features = train_df_2_mts\n",
    "\n",
    "test_labels = test_df_2_mts.pop('label_PM072')\n",
    "test_features = test_df_2_mts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Esto es ESTANDARIZACIÓN\n",
    "train_mean = train_features.mean()\n",
    "train_std = train_features.std()\n",
    "\n",
    "train_features = (train_features - train_mean) / train_std\n",
    "test_features = (test_features - train_mean) / train_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Entrenamiento\n",
    "\n",
    "Nótese que en la función `model.fit` se incluye la opción `validation_split=0.1`. De esta\n",
    "manera se usará un `1O%` **de los datos del conjunto de entrenamiento para validación.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 25 == 0: print('\\n')\n",
    "    print('.', end='')\n",
    "\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),\n",
    "        PrintDot()\n",
    "    ]\n",
    "\n",
    "def build_and_compile_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.Dense(16,kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu', input_shape=(len(train_features.columns),) ),\n",
    "      layers.Dense(16, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(16, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "#kernel_regularizer=regularizers.l2(0.0001),\n",
    "#layers.Dropout(0.2),\n",
    "\n",
    "  model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['mae']\n",
    "  )\n",
    "\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_and_compile_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    verbose=0,\n",
    "    callbacks=get_callbacks(),\n",
    "    batch_size=32,\n",
    "    epochs=100\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Se guardan las predicciones en un df\n",
    "predictions = pd.DataFrame(model.predict(test_features), columns = ['predictions'])\n",
    "\n",
    "# Evaluar el modelo para el conjunto de test\n",
    "loss, mae = model.evaluate(test_features, test_labels, verbose=2)\n",
    "print(\"Loss (MSE): \", loss)\n",
    "print(\"MAE: \", mae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experimento #3\n",
    "\n",
    "Tal y como se indicó en el apartado `Experimentos`, en el **Experimento #3** se tratará de predecir\n",
    "el tráfico en el punto en el que se ubica el sensor `PM072` (CITIUS) en un instante `t` a partir de\n",
    "las mediciones realizadas en un instante `t-x` por los sensores:\n",
    "- `PM020` (Rotonda Galuresa - Avda. Romero Donallo)\n",
    "- `PM076` (Rúa do Horreo - Rotonda Galuresa)\n",
    "- `PM077` (Avda. Romero Donallo - Rotonda Galuresa)\n",
    "- `PM079` (Rúa do Horreo - Rotonda Galuresa)\n",
    "\n",
    "### Análisis dataset Experimento #3\n",
    "\n",
    "En primer lugar, hay que obtener solo aquellas mediciones que hayan sido tomadas por los sensores que resultan\n",
    "de interés para el experimento:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sensors_list = ['PM020', 'PM076', 'PM077', 'PM079', 'PM072']\n",
    "df_3 = df.loc[df['sensor'].isin(sensors_list)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Al igual que antes, veamos algunas estadísticas sobre este conjunto:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_3.describe().transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos un boxplot:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_3.boxplot(column=['car_count'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En este boxplot se pueden ver 3 outalyers muy claros. En la siguiente sección se determinará la causa de dichos valores."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Análisis gráfico Experimento #3\n",
    "\n",
    "Utilizando la función previamente creada se realizarán una serie de gráficas para ver la evolución de los datos del tráfico\n",
    "de manera más intuitiva.\n",
    "\n",
    "A continuación se analizarán las mediciones 'sospechosas' del boxplot anterior:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_3.loc[df_3['car_count'] > 100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resulta interesante ver que las 3 mediciones se produjeron en el mismo instante temporal.\n",
    "\n",
    "En la siguiente gráfica se muestra la evolución del día anterior y siguiente al `2019-11-22` para el\n",
    "sensor `PM079`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "days = pd.date_range(start='2019-11-21', end='2019-11-23', freq='D')\n",
    "plot_sensors_daily_data(df_orig=df_3, days_list = days, sensor='PM079')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En la gráfica correspondiente al `2019-11-22` se puede observar lo comentado en el anterior experimento. Al tratarse de\n",
    "un error en las mediciones estos datos deben ser eliminados del conjunto:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_3 = df_3[df_3['car_count'] < 100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El resto de mediciones se encuentran dentro de lo normal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparación dataset Experimento #3\n",
    "\n",
    "#### Label PM072\n",
    "\n",
    "Para este experimento, el vector de características que necesita el modelo tiene la siguiente forma:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "column_names = ['datetime', 'car_count_PM020', 'car_count_PM076', 'car_count_PM077', 'car_count_PM079', 'label_PM072']\n",
    "pd.DataFrame(columns = column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuación se utiliza la función para preparar el dataset para el Experimento #3:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sensors_list = ['PM020', 'PM076', 'PM077', 'PM079']\n",
    "df_3 = prepare_df(df_3, sensors_list, 'PM072', x = 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tiempo\n",
    "\n",
    "Para codificar el tiempo se usará la misma función previamente definida:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_3 = encode_time_sin_cos(df_3)\n",
    "df_3.sample()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementación Perceptrón Multicapa (MLP)\n",
    "\n",
    "#### División del dataset, Separación y Normalización"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Shuffle\n",
    "df_3_shuffled=df_3.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = len(df_3_shuffled)\n",
    "train_df_3 = df_3_shuffled[0:int(n*0.90)]\n",
    "test_df_3 = df_3_shuffled[int(n*0.90):]\n",
    "\n",
    "# Guardo las columnas del datetime para ambos conjuntos\n",
    "train_dates = train_df_3.pop('datetime')\n",
    "test_dates = test_df_3.pop('datetime')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels = train_df_3.pop('label_PM072')\n",
    "train_features = train_df_3\n",
    "\n",
    "test_labels = test_df_3.pop('label_PM072')\n",
    "test_features = test_df_3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_mean = train_features.mean()\n",
    "train_std = train_features.std()\n",
    "\n",
    "train_features = (train_features - train_mean) / train_std\n",
    "test_features = (test_features - train_mean) / train_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Entrenamiento\n",
    "\n",
    "Nótese que en la función `model.fit` se incluye la opción `validation_split=0.1`. De esta\n",
    "manera se usará un `1O%` **de los datos del conjunto de entrenamiento para validación.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 25 == 0: print('\\n')\n",
    "    print('.', end='')\n",
    "\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),\n",
    "        PrintDot()\n",
    "    ]\n",
    "\n",
    "def build_and_compile_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.Dense(64, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu', input_shape=(len(train_features.columns),) ),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Dense(64, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Dense(64, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "#kernel_regularizer=regularizers.l2(0.0001),\n",
    "#layers.Dropout(0.5),\n",
    "\n",
    "\n",
    "  model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['mae']\n",
    "  )\n",
    "\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_and_compile_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    verbose=0,\n",
    "    callbacks=get_callbacks(),\n",
    "    batch_size=32,\n",
    "    epochs=200\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Se guardan las predicciones en un df\n",
    "predictions = pd.DataFrame(model.predict(test_features), columns = ['predictions'])\n",
    "\n",
    "# Evaluar el modelo para el conjunto de test\n",
    "loss, mae = model.evaluate(test_features, test_labels, verbose=2)\n",
    "mae"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_predictions(test_dates, test_labels, predictions, freq = 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementación MLP con Múltiples Timesteps\n",
    "\n",
    "Hasta ahora, en este `Experimento #3`, el entrenamiento para la predicción en el sensor `PM072` en el instante `t`\n",
    "se realizaba con la información procedente de los sensores `PM020, PM076, PM077 y PM079` en el instante `t-5minutos`.\n",
    "\n",
    "**Resulta interesante ver si la predicción se puede mejorar si se le proporciona a la red información de `10 y 15 minutos antes`**\n",
    "\n",
    "Ahora mismo el dataset del `Experimento #3` tiene la siguiente forma:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizando la función anteriormente definida se creará el DataFrama con la información necesaria para el Experimento:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_3_multi_timestep = prepare_multi_timestep_df(df_3)\n",
    "df_3_multi_timestep"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### División, Separación y Normalización"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "df_3_mts_shuffled=df_3_multi_timestep.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = len(df_3_mts_shuffled)\n",
    "train_df_3_mts = df_3_mts_shuffled[0:int(n*0.90)]\n",
    "test_df_3_mts = df_3_mts_shuffled[int(n*0.90):]\n",
    "\n",
    "# Guardo las columnas del datetime para ambos conjuntos\n",
    "train_dates = train_df_3_mts.pop('datetime')\n",
    "test_dates = test_df_3_mts.pop('datetime')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels = train_df_3_mts.pop('label_PM072')\n",
    "train_features = train_df_3_mts\n",
    "\n",
    "test_labels = test_df_3_mts.pop('label_PM072')\n",
    "test_features = test_df_3_mts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Esto es ESTANDARIZACIÓN\n",
    "train_mean = train_features.mean()\n",
    "train_std = train_features.std()\n",
    "\n",
    "train_features = (train_features - train_mean) / train_std\n",
    "test_features = (test_features - train_mean) / train_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Entrenamiento\n",
    "\n",
    "Nótese que en la función `model.fit` se incluye la opción `validation_split=0.1`. De esta\n",
    "manera se usará un `1O%` **de los datos del conjunto de entrenamiento para validación.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 25 == 0: print('\\n')\n",
    "    print('.', end='')\n",
    "\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),\n",
    "        PrintDot()\n",
    "    ]\n",
    "\n",
    "def build_and_compile_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.Dense(32, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu', input_shape=(len(train_features.columns),) ),\n",
    "      layers.Dense(64, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(32, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(16, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "#kernel_regularizer=regularizers.l2(0.0001),\n",
    "#layers.Dropout(0.2),\n",
    "\n",
    "  model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        metrics=['mae']\n",
    "  )\n",
    "\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_and_compile_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    verbose=0,\n",
    "    callbacks=get_callbacks(),\n",
    "    batch_size=32,\n",
    "    epochs=100\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Se guardan las predicciones en un df\n",
    "predictions = pd.DataFrame(model.predict(test_features), columns = ['predictions'])\n",
    "\n",
    "# Evaluar el modelo para el conjunto de test\n",
    "loss, mae = model.evaluate(test_features, test_labels, verbose=2)\n",
    "print(\"Loss (MSE): \", loss)\n",
    "print(\"MAE: \", mae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experimento #4\n",
    "\n",
    "Tal y como se indicó en el apartado `Experimentos`, en el **Experimento #4** se tratará de predecir\n",
    "el tráfico en el punto en el que se ubica el sensor `PM072` (CITIUS) en un instante `t a partir de\n",
    "las mediciones realizadas en un instante `t-x` por **todos los sensores de la ciudad.**\n",
    "\n",
    "### Análisis dataset Experimento #4\n",
    "\n",
    "En este caso se trabaja con todo el dataset, por lo que no es necesario especificar los sensores en concreto:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "df_4 = df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Al igual que antes, veamos algunas estadísticas sobre este conjunto:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "               count       mean        std  min  25%  50%   75%    max\ncar_count  2904379.0  12.220462  18.023441  0.0  0.0  4.0  19.0  806.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>car_count</th>\n      <td>2904379.0</td>\n      <td>12.220462</td>\n      <td>18.023441</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>19.0</td>\n      <td>806.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4.describe().transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos un boxplot:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 576x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_4.boxplot(column=['car_count'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En este boxplot se puede observar que hay una gran cantidad de mediciones que superan los 100 coches en 5 minutos.\n",
    "Debido a la gran cantidad de mediciones que hay (en torno a 3 millones), resulta imposible realizar un análisis gráfico\n",
    "como se realizó para los experimentos anteriores.\n",
    "\n",
    "Por lo experiencia obtenida durante los anteriores experimentos y aplicando\n",
    "un poco de lógica, se descartarán todas las mediciones que superen un `car_count de 200`. Esto se debe a que en los experimentos\n",
    "anteriores se pudo concluir que eran outlayers debidos a errores o fallos en el funcionamiento de los sensores. Por otra parte,\n",
    "un `car_count de 200` implica un flujo de 40 coches por minuto, lo cual en una ciudad como Santiago de Compostela es bastante.\n",
    "Asimismo, todos los sensores están colocados en vías urbanas en las que hay tan sólo un carril y la velocidad está limitada\n",
    "a 50km/h (como máximo), por lo que aplicando un poco de sentido común, es imposible que pasen 40 coches por minuto de media."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "df_4 = df_4.loc[df_4['car_count'] < 200]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparación dataset Experimento #4\n",
    "\n",
    "#### Label PM072"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuación se utiliza la función para preparar el dataset para el Experimento #3:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "# Selecciono todos los nombres de sensores (sin repetición)\n",
    "sensors_list = df_4['sensor'].unique()\n",
    "# PM072 será el label\n",
    "sensors_list = np.delete(sensors_list,np.where(sensors_list == 'PM072'))\n",
    "# Los ordeno por comodidad\n",
    "sensors_list.sort()\n",
    "# Preparo el dataset\n",
    "df_4 = prepare_df(df_4, sensors_list, 'PM072', x = 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A partir de la experiencia obtenida en los anteriores experimentos, sabemos que hay sensores que nunca contaron un coche;\n",
    "es decir, su columna en este nuevo dataframe es todo 0. Como estos datos no aportan nada, dichas columnas deben ser eliminadas:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "df_4 = df_4.loc[:, (df_4 != 0).any(axis=0)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Además, se ha podido observar que algunas columnas tan solo tienen un par de datos distintos de 0; es decir, tan\n",
    "solo han realizado 2 mediciones de las 36790. Estas columnas también deben ser eliminadas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_count_PM001    24427\n",
      "car_count_PM002    26229\n",
      "car_count_PM003     5715\n",
      "car_count_PM009        2\n",
      "car_count_PM010    24548\n",
      "car_count_PM011    28469\n",
      "car_count_PM013    33414\n",
      "car_count_PM015    36005\n",
      "car_count_PM016    35992\n",
      "car_count_PM017    35318\n",
      "car_count_PM018    36242\n",
      "car_count_PM020    33905\n",
      "car_count_PM021    35488\n",
      "car_count_PM024    34946\n",
      "car_count_PM026    35907\n",
      "car_count_PM028    32930\n",
      "car_count_PM029    32758\n",
      "car_count_PM030    35518\n",
      "car_count_PM031    34367\n",
      "car_count_PM032    35830\n",
      "car_count_PM035    35679\n",
      "car_count_PM036    28380\n",
      "car_count_PM037    30892\n",
      "car_count_PM040    34305\n",
      "car_count_PM043    32789\n",
      "car_count_PM044    35882\n",
      "car_count_PM046    34999\n",
      "car_count_PM047    33620\n",
      "car_count_PM048    29334\n",
      "car_count_PM049    34982\n",
      "car_count_PM050    34719\n",
      "car_count_PM051    29358\n",
      "car_count_PM052    35900\n",
      "car_count_PM053    35477\n",
      "car_count_PM054    34347\n",
      "car_count_PM055    35031\n",
      "car_count_PM056    34650\n",
      "car_count_PM057    33110\n",
      "car_count_PM058    34574\n",
      "car_count_PM059    28354\n",
      "car_count_PM060    31252\n",
      "car_count_PM061        2\n",
      "car_count_PM062    28214\n",
      "car_count_PM063    30066\n",
      "car_count_PM064    30175\n",
      "car_count_PM065    29680\n",
      "car_count_PM066    27424\n",
      "car_count_PM067    30066\n",
      "car_count_PM073    33289\n",
      "car_count_PM074        2\n",
      "car_count_PM075        2\n",
      "car_count_PM076    34614\n",
      "car_count_PM077    31415\n",
      "car_count_PM078    31945\n",
      "car_count_PM079    32949\n",
      "car_count_PM082    31448\n",
      "car_count_PM083    31927\n",
      "car_count_PM084    32969\n",
      "label_PM072        34567\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "xx = df_4.loc[:, df_4.columns != 'datetime']\n",
    "aa = xx.astype(bool).sum(axis=0)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(aa)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En esta lista se puede observar que los sensores `PM009`, `PM061`, `PM074` y `PM075` solo han realizado\n",
    "2 mediciones a lo largo de estos 5 meses."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "to_drop = ['car_count_PM009', 'car_count_PM061', 'car_count_PM074', 'car_count_PM075']\n",
    "df_4 = df_4.drop(to_drop, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tiempo\n",
    "\n",
    "Para codificar el tiempo se usará la misma función previamente definida:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "data": {
      "text/plain": "                 datetime  car_count_PM001  car_count_PM002  car_count_PM003  \\\n17570 2019-12-11 19:30:00                8               18                0   \n\n       car_count_PM010  car_count_PM011  car_count_PM013  car_count_PM015  \\\n17570                0                5               31               51   \n\n       car_count_PM016  car_count_PM017  ...  car_count_PM078  \\\n17570               64               29  ...               22   \n\n       car_count_PM079  car_count_PM082  car_count_PM083  car_count_PM084  \\\n17570               15               25               27               56   \n\n       label_PM072  hour_sin  hour_cos  wday_sin  wday_cos  \n17570           27  -0.92388  0.382683  0.974928 -0.222521  \n\n[1 rows x 60 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>car_count_PM001</th>\n      <th>car_count_PM002</th>\n      <th>car_count_PM003</th>\n      <th>car_count_PM010</th>\n      <th>car_count_PM011</th>\n      <th>car_count_PM013</th>\n      <th>car_count_PM015</th>\n      <th>car_count_PM016</th>\n      <th>car_count_PM017</th>\n      <th>...</th>\n      <th>car_count_PM078</th>\n      <th>car_count_PM079</th>\n      <th>car_count_PM082</th>\n      <th>car_count_PM083</th>\n      <th>car_count_PM084</th>\n      <th>label_PM072</th>\n      <th>hour_sin</th>\n      <th>hour_cos</th>\n      <th>wday_sin</th>\n      <th>wday_cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17570</th>\n      <td>2019-12-11 19:30:00</td>\n      <td>8</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>31</td>\n      <td>51</td>\n      <td>64</td>\n      <td>29</td>\n      <td>...</td>\n      <td>22</td>\n      <td>15</td>\n      <td>25</td>\n      <td>27</td>\n      <td>56</td>\n      <td>27</td>\n      <td>-0.92388</td>\n      <td>0.382683</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 60 columns</p>\n</div>"
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4 = encode_time_sin_cos(df_4)\n",
    "df_4.sample()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementación Perceptrón Multicapa (MLP)\n",
    "\n",
    "#### División del dataset, Separación y Normalización"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Shuffle\n",
    "df_4_shuffled=df_4.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = len(df_4_shuffled)\n",
    "train_df_4 = df_4_shuffled[0:int(n*0.90)]\n",
    "test_df_4 = df_4_shuffled[int(n*0.90):]\n",
    "\n",
    "# Guardo las columnas del datetime para ambos conjuntos\n",
    "train_dates = train_df_4.pop('datetime')\n",
    "test_dates = test_df_4.pop('datetime')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels = train_df_4.pop('label_PM072')\n",
    "train_features = train_df_4\n",
    "\n",
    "test_labels = test_df_4.pop('label_PM072')\n",
    "test_features = test_df_4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_mean = train_features.mean()\n",
    "train_std = train_features.std()\n",
    "\n",
    "train_features = (train_features - train_mean) / train_std\n",
    "test_features = (test_features - train_mean) / train_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Entrenamiento\n",
    "\n",
    "Nótese que en la función `model.fit` se incluye la opción `validation_split=0.1`. De esta\n",
    "manera se usará un `1O%` **de los datos del conjunto de entrenamiento para validación.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 25 == 0: print('\\n')\n",
    "    print('.', end='')\n",
    "\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),\n",
    "        PrintDot()\n",
    "    ]\n",
    "\n",
    "def build_and_compile_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.Dense(32,kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu', input_shape=(len(train_features.columns),) ),\n",
    "      layers.Dense(16,kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(8,kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "#kernel_regularizer=regularizers.l2(0.0001),\n",
    "#layers.Dropout(0.5),\n",
    "\n",
    "  model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        metrics=['mae']\n",
    "  )\n",
    "\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_and_compile_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    verbose=0,\n",
    "    callbacks=get_callbacks(),\n",
    "    batch_size=32,\n",
    "    epochs=200\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Se guardan las predicciones en un df\n",
    "predictions = pd.DataFrame(model.predict(test_features), columns = ['predictions'])\n",
    "\n",
    "# Evaluar el modelo para el conjunto de test\n",
    "loss, mae = model.evaluate(test_features, test_labels, verbose=2)\n",
    "mae"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_predictions(test_dates, test_labels, predictions, freq = 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementación MLP con Múltiples Timesteps\n",
    "\n",
    "Hasta ahora, en este `Experimento #4`, el entrenamiento para la predicción en el sensor `PM072` en el instante `t`\n",
    "se realizaba con la información procedente de todos los sensores disponibles en el instante `t-5minutos`.\n",
    "\n",
    "**Resulta interesante ver si la predicción se puede mejorar si se le proporciona a la red información de `10 y 15 minutos antes`**\n",
    "\n",
    "Ahora mismo el dataset del `Experimento #4` tiene la siguiente forma:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizando la función anteriormente definida se creará el DataFrama con la información necesaria para el Experimento:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_4_multi_timestep = prepare_multi_timestep_df(df_4)\n",
    "df_4_multi_timestep"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### División, Separación y Normalización"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "df_4_mts_shuffled=df_4_multi_timestep.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = len(df_4_mts_shuffled)\n",
    "train_df_4_mts = df_4_mts_shuffled[0:int(n*0.90)]\n",
    "test_df_4_mts = df_4_mts_shuffled[int(n*0.90):]\n",
    "\n",
    "# Guardo las columnas del datetime para ambos conjuntos\n",
    "train_dates = train_df_4_mts.pop('datetime')\n",
    "test_dates = test_df_4_mts.pop('datetime')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels = train_df_4_mts.pop('label_PM072')\n",
    "train_features = train_df_4_mts\n",
    "\n",
    "test_labels = test_df_4_mts.pop('label_PM072')\n",
    "test_features = test_df_4_mts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Esto es ESTANDARIZACIÓN\n",
    "train_mean = train_features.mean()\n",
    "train_std = train_features.std()\n",
    "\n",
    "train_features = (train_features - train_mean) / train_std\n",
    "test_features = (test_features - train_mean) / train_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Entrenamiento\n",
    "\n",
    "Nótese que en la función `model.fit` se incluye la opción `validation_split=0.1`. De esta\n",
    "manera se usará un `1O%` **de los datos del conjunto de entrenamiento para validación.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 25 == 0: print('\\n')\n",
    "    print('.', end='')\n",
    "\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),\n",
    "        PrintDot()\n",
    "    ]\n",
    "\n",
    "def build_and_compile_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.Dense(8, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu', input_shape=(len(train_features.columns),) ),\n",
    "      layers.Dense(8, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "#kernel_regularizer=regularizers.l2(0.0001),\n",
    "#layers.Dropout(0.2),\n",
    "\n",
    "  model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        metrics=['mae']\n",
    "  )\n",
    "\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_and_compile_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.1,\n",
    "    verbose=0,\n",
    "    callbacks=get_callbacks(),\n",
    "    batch_size=32,\n",
    "    epochs=100\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Se guardan las predicciones en un df\n",
    "predictions = pd.DataFrame(model.predict(test_features), columns = ['predictions'])\n",
    "\n",
    "# Evaluar el modelo para el conjunto de test\n",
    "loss, mae = model.evaluate(test_features, test_labels, verbose=2)\n",
    "print(\"Loss (MSE): \", loss)\n",
    "print(\"MAE: \", mae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementación RNN\n",
    "\n",
    "#### Implementación LSTM\n",
    "\n",
    "En esta sección se tratará la implementación del modelo con LSTM.\n",
    "\n",
    "Ahora mismo el dataset para el `Experimento #4` tiene las siguientes características:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "data": {
      "text/plain": "                 datetime  car_count_PM001  car_count_PM002  car_count_PM003  \\\n29900 2020-02-03 06:15:00                3                2                0   \n\n       car_count_PM010  car_count_PM011  car_count_PM013  car_count_PM015  \\\n29900                0                5                4               28   \n\n       car_count_PM016  car_count_PM017  ...  car_count_PM078  \\\n29900               18                8  ...               14   \n\n       car_count_PM079  car_count_PM082  car_count_PM083  car_count_PM084  \\\n29900                4                5                6                8   \n\n       label_PM072  hour_sin  hour_cos  wday_sin  wday_cos  \n29900           22  0.997859 -0.065403       0.0       1.0  \n\n[1 rows x 60 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>car_count_PM001</th>\n      <th>car_count_PM002</th>\n      <th>car_count_PM003</th>\n      <th>car_count_PM010</th>\n      <th>car_count_PM011</th>\n      <th>car_count_PM013</th>\n      <th>car_count_PM015</th>\n      <th>car_count_PM016</th>\n      <th>car_count_PM017</th>\n      <th>...</th>\n      <th>car_count_PM078</th>\n      <th>car_count_PM079</th>\n      <th>car_count_PM082</th>\n      <th>car_count_PM083</th>\n      <th>car_count_PM084</th>\n      <th>label_PM072</th>\n      <th>hour_sin</th>\n      <th>hour_cos</th>\n      <th>wday_sin</th>\n      <th>wday_cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29900</th>\n      <td>2020-02-03 06:15:00</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>28</td>\n      <td>18</td>\n      <td>8</td>\n      <td>...</td>\n      <td>14</td>\n      <td>4</td>\n      <td>5</td>\n      <td>6</td>\n      <td>8</td>\n      <td>22</td>\n      <td>0.997859</td>\n      <td>-0.065403</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 60 columns</p>\n</div>"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4_rnn = df_4.copy(deep = True)\n",
    "df_4.sample()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tal y como se ha comentado en `Definición RNN`, este tipo de arquitectura es capaz\n",
    "de modelar el tiempo de forma explícita, por lo que ya *no es necesario* que se introduzca\n",
    "la información temporal:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "to_drop = ['wday_sin', 'wday_cos', 'hour_sin', 'hour_cos']\n",
    "df_4_rnn.drop(to_drop, axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por otra parte, para que la red pueda modelar el tiempo de manera correcta, es necesario\n",
    "que los datos que reciba estén ordenados temporalmente; es decir, por el campo `datetime`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "data": {
      "text/plain": "                 datetime  car_count_PM001  car_count_PM002  car_count_PM003  \\\n0     2019-10-01 00:00:00                0                0                0   \n1     2019-10-01 00:05:00                1                0                0   \n2     2019-10-01 00:10:00                0                0                0   \n3     2019-10-01 00:15:00                0                0                0   \n4     2019-10-01 00:20:00                0                4                0   \n...                   ...              ...              ...              ...   \n36785 2020-02-29 06:50:00                0                0                5   \n36786 2020-02-29 06:55:00                0                0                5   \n36787 2020-02-29 07:00:00                0                0                2   \n36788 2020-02-29 07:05:00                0                0                6   \n36789 2020-02-29 07:10:00                0                0                5   \n\n       car_count_PM010  car_count_PM011  car_count_PM013  car_count_PM015  \\\n0                   18                1                1                1   \n1                   10                0                3                1   \n2                   14                0                0                0   \n3                   12                1                1                3   \n4                   20                0                1                1   \n...                ...              ...              ...              ...   \n36785                0                2                4               13   \n36786                2                0                5               12   \n36787                1                0                2               14   \n36788                3                1                3                9   \n36789                0                0                5               16   \n\n       car_count_PM016  car_count_PM017  ...  car_count_PM067  \\\n0                    4                4  ...                0   \n1                    1                1  ...                0   \n2                    0                1  ...                1   \n3                    1                2  ...                0   \n4                    0                1  ...                0   \n...                ...              ...  ...              ...   \n36785               15                9  ...                6   \n36786               11               15  ...                0   \n36787               16                5  ...                4   \n36788               17               11  ...                4   \n36789               13                8  ...                3   \n\n       car_count_PM073  car_count_PM076  car_count_PM077  car_count_PM078  \\\n0                    3                2                1                2   \n1                    0                2                0                0   \n2                    0                0                0                0   \n3                    0                0                0                0   \n4                    2                1                0                0   \n...                ...              ...              ...              ...   \n36785                8                4                3                7   \n36786               13                6                2                3   \n36787                9                3                4                8   \n36788               12                4                2                5   \n36789               10                6                3                6   \n\n       car_count_PM079  car_count_PM082  car_count_PM083  car_count_PM084  \\\n0                    0                1                1                1   \n1                    1                0                0                1   \n2                    0                0                0                0   \n3                    0                0                1                0   \n4                    1                0                1                0   \n...                ...              ...              ...              ...   \n36785                5                7                4                9   \n36786                2                1                3                8   \n36787                3                3                6                2   \n36788                4                5                4                3   \n36789                3                2                1                2   \n\n       label_PM072  \n0                0  \n1                0  \n2                0  \n3                0  \n4                1  \n...            ...  \n36785            3  \n36786            4  \n36787            6  \n36788           12  \n36789            3  \n\n[36790 rows x 56 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>car_count_PM001</th>\n      <th>car_count_PM002</th>\n      <th>car_count_PM003</th>\n      <th>car_count_PM010</th>\n      <th>car_count_PM011</th>\n      <th>car_count_PM013</th>\n      <th>car_count_PM015</th>\n      <th>car_count_PM016</th>\n      <th>car_count_PM017</th>\n      <th>...</th>\n      <th>car_count_PM067</th>\n      <th>car_count_PM073</th>\n      <th>car_count_PM076</th>\n      <th>car_count_PM077</th>\n      <th>car_count_PM078</th>\n      <th>car_count_PM079</th>\n      <th>car_count_PM082</th>\n      <th>car_count_PM083</th>\n      <th>car_count_PM084</th>\n      <th>label_PM072</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-10-01 00:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-10-01 00:05:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-10-01 00:10:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-10-01 00:15:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-10-01 00:20:00</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>20</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36785</th>\n      <td>2020-02-29 06:50:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>13</td>\n      <td>15</td>\n      <td>9</td>\n      <td>...</td>\n      <td>6</td>\n      <td>8</td>\n      <td>4</td>\n      <td>3</td>\n      <td>7</td>\n      <td>5</td>\n      <td>7</td>\n      <td>4</td>\n      <td>9</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>36786</th>\n      <td>2020-02-29 06:55:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>5</td>\n      <td>12</td>\n      <td>11</td>\n      <td>15</td>\n      <td>...</td>\n      <td>0</td>\n      <td>13</td>\n      <td>6</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>8</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>36787</th>\n      <td>2020-02-29 07:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>14</td>\n      <td>16</td>\n      <td>5</td>\n      <td>...</td>\n      <td>4</td>\n      <td>9</td>\n      <td>3</td>\n      <td>4</td>\n      <td>8</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6</td>\n      <td>2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>36788</th>\n      <td>2020-02-29 07:05:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>9</td>\n      <td>17</td>\n      <td>11</td>\n      <td>...</td>\n      <td>4</td>\n      <td>12</td>\n      <td>4</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>5</td>\n      <td>4</td>\n      <td>3</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>36789</th>\n      <td>2020-02-29 07:10:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>16</td>\n      <td>13</td>\n      <td>8</td>\n      <td>...</td>\n      <td>3</td>\n      <td>10</td>\n      <td>6</td>\n      <td>3</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>36790 rows × 56 columns</p>\n</div>"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4_rnn.sort_values(by=['datetime'], ignore_index = True , inplace = True)\n",
    "df_4_rnn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### División del dataset, Separación y Normalización\n",
    "\n",
    "Cabe destacar que ahora, al utilizar una RNN (LSTM) NO se debe hacer el shuffle que\n",
    "se hizo previamente al trabajar con el MLP."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "n = len(df_4_rnn)\n",
    "train_df_4_rnn = df_4_rnn[0:int(n*0.90)]\n",
    "test_df_4_rnn = df_4_rnn[int(n*0.90):]\n",
    "\n",
    "# Guardo las columnas del datetime para ambos conjuntos\n",
    "train_dates = train_df_4_rnn.pop('datetime')\n",
    "test_dates = test_df_4_rnn.pop('datetime')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "train_labels = train_df_4_rnn.pop('label_PM072')\n",
    "train_features = train_df_4_rnn\n",
    "\n",
    "test_labels = test_df_4_rnn.pop('label_PM072')\n",
    "test_features = test_df_4_rnn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "# Esto es ESTANDARIZACIÓN\n",
    "train_mean = train_features.mean()\n",
    "train_std = train_features.std()\n",
    "\n",
    "train_features = (train_features - train_mean) / train_std\n",
    "test_features = (test_features - train_mean) / train_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Entrada celda LSTM\n",
    "\n",
    "Ahora que se ha realizado todo el proceso anterior, ya es posible crear la entrada 3D. Pero antes, se debe tener en cuenta que,\n",
    "al igual que se ha visto en la sección `Implementación MLP con Múltiples Timesteps`, el dataset no presenta TODAS las mediciones.\n",
    "\n",
    "El modelo debe recibir la información de los instantes `t-5, t-10 y t-15`. Para ello, es necesario seleccionar solo\n",
    "aquellas filas para las que hay dos mediciones en los dos instantes temporales posteriores. **Esas mediciones en esos\n",
    "3 instantes será la entrada 3D del modelo.**\n",
    "\n",
    "Asimismo, se deben almacenar solo los labels y fechas correspondientes a la medición en el instante `t-5`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "data": {
      "text/plain": "       car_count_PM001  car_count_PM002  car_count_PM003  car_count_PM010  \\\n0            -0.984684        -0.580757        -0.233118         7.639171   \n1            -0.780560        -0.580757        -0.233118         3.859333   \n2            -0.984684        -0.580757        -0.233118         5.749252   \n3            -0.984684        -0.580757        -0.233118         4.804293   \n4            -0.984684        -0.336222        -0.233118         8.584130   \n...                ...              ...              ...              ...   \n33106        -0.984684        -0.580757         0.185379         0.079496   \n33107        -0.984684        -0.580757         0.394628        -0.865464   \n33108        -0.984684        -0.580757         0.185379        -0.865464   \n33109        -0.984684        -0.580757         0.185379        -0.865464   \n33110        -0.984684        -0.580757         0.394628        -0.865464   \n\n       car_count_PM011  car_count_PM013  car_count_PM015  car_count_PM016  \\\n0            -0.700904        -1.180375        -1.370037        -1.213668   \n1            -0.925876        -1.034538        -1.370037        -1.332409   \n2            -0.925876        -1.253294        -1.411152        -1.371989   \n3            -0.700904        -1.180375        -1.287808        -1.332409   \n4            -0.925876        -1.180375        -1.370037        -1.371989   \n...                ...              ...              ...              ...   \n33106        -0.925876        -1.107457        -1.041121        -1.213668   \n33107         0.423955        -0.888701        -0.876663        -1.015767   \n33108        -0.700904        -0.888701        -0.958892        -1.015767   \n33109        -0.475932        -1.107457        -0.712205        -1.292828   \n33110        -0.250961        -1.107457        -1.205579        -1.015767   \n\n       car_count_PM017  car_count_PM018  ...  car_count_PM066  \\\n0            -1.163273        -1.209683  ...        -0.727997   \n1            -1.348819        -1.325268  ...        -0.727997   \n2            -1.348819        -1.325268  ...        -0.727997   \n3            -1.286970        -1.325268  ...        -0.727997   \n4            -1.348819        -1.325268  ...        -0.727997   \n...                ...              ...  ...              ...   \n33106        -1.225122        -1.209683  ...        -0.727997   \n33107        -1.039575        -1.209683  ...        -0.727997   \n33108        -1.039575        -1.132627  ...        -0.727997   \n33109        -1.225122        -1.209683  ...        -0.616157   \n33110        -1.225122        -1.094099  ...        -0.616157   \n\n       car_count_PM067  car_count_PM073  car_count_PM076  car_count_PM077  \\\n0            -1.169531        -1.023905        -1.249762        -1.135613   \n1            -1.169531        -1.184304        -1.249762        -1.259739   \n2            -1.048958        -1.184304        -1.448232        -1.259739   \n3            -1.169531        -1.184304        -1.448232        -1.259739   \n4            -1.169531        -1.077371        -1.348997        -1.259739   \n...                ...              ...              ...              ...   \n33106        -1.169531        -0.916971        -1.150527        -1.259739   \n33107        -1.169531        -0.916971        -1.150527        -1.259739   \n33108        -1.169531        -0.863505        -1.051292        -1.135613   \n33109        -1.169531        -1.077371        -0.852822        -1.135613   \n33110         0.880199        -0.649638        -1.051292        -1.011486   \n\n       car_count_PM078  car_count_PM079  car_count_PM082  car_count_PM083  \\\n0            -1.048099        -1.341570        -1.041063         -1.10630   \n1            -1.244879        -1.199747        -1.109060         -1.20893   \n2            -1.244879        -1.341570        -1.109060         -1.20893   \n3            -1.244879        -1.341570        -1.109060         -1.10630   \n4            -1.244879        -1.199747        -1.109060         -1.10630   \n...                ...              ...              ...              ...   \n33106        -1.048099        -1.341570        -1.041063         -1.10630   \n33107        -0.851319        -0.774279        -1.109060         -1.00367   \n33108        -0.752929        -0.916102        -1.109060         -1.00367   \n33109        -1.048099        -1.057924        -1.041063         -1.20893   \n33110        -1.048099        -1.057924        -1.041063         -1.10630   \n\n       car_count_PM084  \n0            -1.132052  \n1            -1.132052  \n2            -1.176565  \n3            -1.176565  \n4            -1.176565  \n...                ...  \n33106        -1.176565  \n33107        -1.087539  \n33108        -1.132052  \n33109        -1.087539  \n33110        -1.087539  \n\n[33111 rows x 54 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>car_count_PM001</th>\n      <th>car_count_PM002</th>\n      <th>car_count_PM003</th>\n      <th>car_count_PM010</th>\n      <th>car_count_PM011</th>\n      <th>car_count_PM013</th>\n      <th>car_count_PM015</th>\n      <th>car_count_PM016</th>\n      <th>car_count_PM017</th>\n      <th>car_count_PM018</th>\n      <th>...</th>\n      <th>car_count_PM066</th>\n      <th>car_count_PM067</th>\n      <th>car_count_PM073</th>\n      <th>car_count_PM076</th>\n      <th>car_count_PM077</th>\n      <th>car_count_PM078</th>\n      <th>car_count_PM079</th>\n      <th>car_count_PM082</th>\n      <th>car_count_PM083</th>\n      <th>car_count_PM084</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.984684</td>\n      <td>-0.580757</td>\n      <td>-0.233118</td>\n      <td>7.639171</td>\n      <td>-0.700904</td>\n      <td>-1.180375</td>\n      <td>-1.370037</td>\n      <td>-1.213668</td>\n      <td>-1.163273</td>\n      <td>-1.209683</td>\n      <td>...</td>\n      <td>-0.727997</td>\n      <td>-1.169531</td>\n      <td>-1.023905</td>\n      <td>-1.249762</td>\n      <td>-1.135613</td>\n      <td>-1.048099</td>\n      <td>-1.341570</td>\n      <td>-1.041063</td>\n      <td>-1.10630</td>\n      <td>-1.132052</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.780560</td>\n      <td>-0.580757</td>\n      <td>-0.233118</td>\n      <td>3.859333</td>\n      <td>-0.925876</td>\n      <td>-1.034538</td>\n      <td>-1.370037</td>\n      <td>-1.332409</td>\n      <td>-1.348819</td>\n      <td>-1.325268</td>\n      <td>...</td>\n      <td>-0.727997</td>\n      <td>-1.169531</td>\n      <td>-1.184304</td>\n      <td>-1.249762</td>\n      <td>-1.259739</td>\n      <td>-1.244879</td>\n      <td>-1.199747</td>\n      <td>-1.109060</td>\n      <td>-1.20893</td>\n      <td>-1.132052</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.984684</td>\n      <td>-0.580757</td>\n      <td>-0.233118</td>\n      <td>5.749252</td>\n      <td>-0.925876</td>\n      <td>-1.253294</td>\n      <td>-1.411152</td>\n      <td>-1.371989</td>\n      <td>-1.348819</td>\n      <td>-1.325268</td>\n      <td>...</td>\n      <td>-0.727997</td>\n      <td>-1.048958</td>\n      <td>-1.184304</td>\n      <td>-1.448232</td>\n      <td>-1.259739</td>\n      <td>-1.244879</td>\n      <td>-1.341570</td>\n      <td>-1.109060</td>\n      <td>-1.20893</td>\n      <td>-1.176565</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.984684</td>\n      <td>-0.580757</td>\n      <td>-0.233118</td>\n      <td>4.804293</td>\n      <td>-0.700904</td>\n      <td>-1.180375</td>\n      <td>-1.287808</td>\n      <td>-1.332409</td>\n      <td>-1.286970</td>\n      <td>-1.325268</td>\n      <td>...</td>\n      <td>-0.727997</td>\n      <td>-1.169531</td>\n      <td>-1.184304</td>\n      <td>-1.448232</td>\n      <td>-1.259739</td>\n      <td>-1.244879</td>\n      <td>-1.341570</td>\n      <td>-1.109060</td>\n      <td>-1.10630</td>\n      <td>-1.176565</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.984684</td>\n      <td>-0.336222</td>\n      <td>-0.233118</td>\n      <td>8.584130</td>\n      <td>-0.925876</td>\n      <td>-1.180375</td>\n      <td>-1.370037</td>\n      <td>-1.371989</td>\n      <td>-1.348819</td>\n      <td>-1.325268</td>\n      <td>...</td>\n      <td>-0.727997</td>\n      <td>-1.169531</td>\n      <td>-1.077371</td>\n      <td>-1.348997</td>\n      <td>-1.259739</td>\n      <td>-1.244879</td>\n      <td>-1.199747</td>\n      <td>-1.109060</td>\n      <td>-1.10630</td>\n      <td>-1.176565</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33106</th>\n      <td>-0.984684</td>\n      <td>-0.580757</td>\n      <td>0.185379</td>\n      <td>0.079496</td>\n      <td>-0.925876</td>\n      <td>-1.107457</td>\n      <td>-1.041121</td>\n      <td>-1.213668</td>\n      <td>-1.225122</td>\n      <td>-1.209683</td>\n      <td>...</td>\n      <td>-0.727997</td>\n      <td>-1.169531</td>\n      <td>-0.916971</td>\n      <td>-1.150527</td>\n      <td>-1.259739</td>\n      <td>-1.048099</td>\n      <td>-1.341570</td>\n      <td>-1.041063</td>\n      <td>-1.10630</td>\n      <td>-1.176565</td>\n    </tr>\n    <tr>\n      <th>33107</th>\n      <td>-0.984684</td>\n      <td>-0.580757</td>\n      <td>0.394628</td>\n      <td>-0.865464</td>\n      <td>0.423955</td>\n      <td>-0.888701</td>\n      <td>-0.876663</td>\n      <td>-1.015767</td>\n      <td>-1.039575</td>\n      <td>-1.209683</td>\n      <td>...</td>\n      <td>-0.727997</td>\n      <td>-1.169531</td>\n      <td>-0.916971</td>\n      <td>-1.150527</td>\n      <td>-1.259739</td>\n      <td>-0.851319</td>\n      <td>-0.774279</td>\n      <td>-1.109060</td>\n      <td>-1.00367</td>\n      <td>-1.087539</td>\n    </tr>\n    <tr>\n      <th>33108</th>\n      <td>-0.984684</td>\n      <td>-0.580757</td>\n      <td>0.185379</td>\n      <td>-0.865464</td>\n      <td>-0.700904</td>\n      <td>-0.888701</td>\n      <td>-0.958892</td>\n      <td>-1.015767</td>\n      <td>-1.039575</td>\n      <td>-1.132627</td>\n      <td>...</td>\n      <td>-0.727997</td>\n      <td>-1.169531</td>\n      <td>-0.863505</td>\n      <td>-1.051292</td>\n      <td>-1.135613</td>\n      <td>-0.752929</td>\n      <td>-0.916102</td>\n      <td>-1.109060</td>\n      <td>-1.00367</td>\n      <td>-1.132052</td>\n    </tr>\n    <tr>\n      <th>33109</th>\n      <td>-0.984684</td>\n      <td>-0.580757</td>\n      <td>0.185379</td>\n      <td>-0.865464</td>\n      <td>-0.475932</td>\n      <td>-1.107457</td>\n      <td>-0.712205</td>\n      <td>-1.292828</td>\n      <td>-1.225122</td>\n      <td>-1.209683</td>\n      <td>...</td>\n      <td>-0.616157</td>\n      <td>-1.169531</td>\n      <td>-1.077371</td>\n      <td>-0.852822</td>\n      <td>-1.135613</td>\n      <td>-1.048099</td>\n      <td>-1.057924</td>\n      <td>-1.041063</td>\n      <td>-1.20893</td>\n      <td>-1.087539</td>\n    </tr>\n    <tr>\n      <th>33110</th>\n      <td>-0.984684</td>\n      <td>-0.580757</td>\n      <td>0.394628</td>\n      <td>-0.865464</td>\n      <td>-0.250961</td>\n      <td>-1.107457</td>\n      <td>-1.205579</td>\n      <td>-1.015767</td>\n      <td>-1.225122</td>\n      <td>-1.094099</td>\n      <td>...</td>\n      <td>-0.616157</td>\n      <td>0.880199</td>\n      <td>-0.649638</td>\n      <td>-1.051292</td>\n      <td>-1.011486</td>\n      <td>-1.048099</td>\n      <td>-1.057924</td>\n      <td>-1.041063</td>\n      <td>-1.10630</td>\n      <td>-1.087539</td>\n    </tr>\n  </tbody>\n</table>\n<p>33111 rows × 54 columns</p>\n</div>"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "data": {
      "text/plain": "0         0\n1         0\n2         0\n3         0\n4         1\n         ..\n33106    21\n33107    15\n33108    18\n33109    18\n33110    12\nName: label_PM072, Length: 33111, dtype: int64"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_inputs.shape:  (32362, 3, 54)\n",
      "train_outputs.shape:  (32362,)\n",
      "test_inputs.shape:  (3624, 3, 54)\n",
      "test_outputs.shape:  (3624,)\n"
     ]
    }
   ],
   "source": [
    "train_inputs, train_outputs, train_dates = create_LSTM_data(train_features, train_labels, train_dates)\n",
    "test_inputs, test_outputs, test_dates = create_LSTM_data(test_features, test_labels, test_dates)\n",
    "\n",
    "print('train_inputs.shape: ', train_inputs.shape)\n",
    "print('train_outputs.shape: ', train_outputs.shape)\n",
    "print('test_inputs.shape: ', test_inputs.shape)\n",
    "print('test_outputs.shape: ', test_outputs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[-0.98468409, -0.58075721, -0.23311766, ..., -1.04106311,\n         -1.10629991, -1.13205207],\n        [-0.78056031, -0.58075721, -0.23311766, ..., -1.10906046,\n         -1.20893018, -1.13205207],\n        [-0.98468409, -0.58075721, -0.23311766, ..., -1.10906046,\n         -1.20893018, -1.17656513]],\n\n       [[-0.78056031, -0.58075721, -0.23311766, ..., -1.10906046,\n         -1.20893018, -1.13205207],\n        [-0.98468409, -0.58075721, -0.23311766, ..., -1.10906046,\n         -1.20893018, -1.17656513],\n        [-0.98468409, -0.58075721, -0.23311766, ..., -1.10906046,\n         -1.10629991, -1.17656513]],\n\n       [[-0.98468409, -0.58075721, -0.23311766, ..., -1.10906046,\n         -1.20893018, -1.17656513],\n        [-0.98468409, -0.58075721, -0.23311766, ..., -1.10906046,\n         -1.10629991, -1.17656513],\n        [-0.98468409, -0.33622203, -0.23311766, ..., -1.10906046,\n         -1.10629991, -1.17656513]],\n\n       ...,\n\n       [[-0.98468409, -0.58075721,  0.18537935, ..., -1.04106311,\n         -1.10629991, -1.17656513],\n        [-0.98468409, -0.58075721,  0.39462785, ..., -1.10906046,\n         -1.00366963, -1.08753902],\n        [-0.98468409, -0.58075721,  0.18537935, ..., -1.10906046,\n         -1.00366963, -1.13205207]],\n\n       [[-0.98468409, -0.58075721,  0.39462785, ..., -1.10906046,\n         -1.00366963, -1.08753902],\n        [-0.98468409, -0.58075721,  0.18537935, ..., -1.10906046,\n         -1.00366963, -1.13205207],\n        [-0.98468409, -0.58075721,  0.18537935, ..., -1.04106311,\n         -1.20893018, -1.08753902]],\n\n       [[-0.98468409, -0.58075721,  0.18537935, ..., -1.10906046,\n         -1.00366963, -1.13205207],\n        [-0.98468409, -0.58075721,  0.18537935, ..., -1.04106311,\n         -1.20893018, -1.08753902],\n        [-0.98468409, -0.58075721,  0.39462785, ..., -1.04106311,\n         -1.10629991, -1.08753902]]])"
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  0,  1, ..., 18, 18, 12])"
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como se puede observar, cada ejemplo tiene las mediciones correspondientes a `3 instantes temporales` y tiene\n",
    "asociada la medición realizada por el sensor `PM072` en el último instante temporal.\n",
    "\n",
    "#### Entrenamiento"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 25 == 0: print('\\n')\n",
    "    print('.', end='')\n",
    "\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50),\n",
    "        PrintDot()\n",
    "    ]\n",
    "\n",
    "def build_and_compile_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.LSTM(64, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu', return_sequences=True,\n",
    "                   input_shape=(train_inputs.shape[1], train_inputs.shape[2]) ),\n",
    "      layers.Dropout(0.5),\n",
    "      layers.LSTM(64, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                   activation='relu'),\n",
    "      layers.Dropout(0.5),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "#kernel_regularizer=regularizers.l2(0.0001),\n",
    "#layers.Dropout(0.5),\n",
    "\n",
    "  model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        metrics=['mae']\n",
    "  )\n",
    "\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_24 (LSTM)               (None, 3, 64)             30464     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 63,553\n",
      "Trainable params: 63,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_and_compile_model()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ".........................\n",
      "\n",
      ".........................\n",
      "\n",
      ".........................\n",
      "\n",
      ".........................\n",
      "\n",
      ".........................\n",
      "\n",
      ".........................\n",
      "\n",
      ".........................\n",
      "\n",
      ".........................CPU times: user 23min 18s, sys: 3min 27s, total: 26min 45s\n",
      "Wall time: 11min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(\n",
    "    train_inputs,\n",
    "    train_outputs,\n",
    "    validation_split=0.1,\n",
    "    verbose=0,\n",
    "    shuffle = False,\n",
    "    callbacks=get_callbacks(),\n",
    "    batch_size=32,\n",
    "    epochs=200\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "data": {
      "text/plain": "          loss       mae   val_loss   val_mae  epoch\n195  47.714134  5.060512  92.017815  7.147583    195\n196  47.279671  5.048480  92.864632  7.185225    196\n197  46.961765  5.031456  84.242783  6.838760    197\n198  46.870884  5.030772  89.924393  7.068830    198\n199  47.933479  5.066584  85.701118  6.889493    199",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>mae</th>\n      <th>val_loss</th>\n      <th>val_mae</th>\n      <th>epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>195</th>\n      <td>47.714134</td>\n      <td>5.060512</td>\n      <td>92.017815</td>\n      <td>7.147583</td>\n      <td>195</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>47.279671</td>\n      <td>5.048480</td>\n      <td>92.864632</td>\n      <td>7.185225</td>\n      <td>196</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>46.961765</td>\n      <td>5.031456</td>\n      <td>84.242783</td>\n      <td>6.838760</td>\n      <td>197</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>46.870884</td>\n      <td>5.030772</td>\n      <td>89.924393</td>\n      <td>7.068830</td>\n      <td>198</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>47.933479</td>\n      <td>5.066584</td>\n      <td>85.701118</td>\n      <td>6.889493</td>\n      <td>199</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([20, 70])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 - 0s - loss: 98.7604 - mae: 7.4739\n",
      "Loss (MSE):  98.76040649414062\n",
      "MAE:  7.473855972290039\n"
     ]
    }
   ],
   "source": [
    "# Se guardan las predicciones en un df\n",
    "predictions = pd.DataFrame(model.predict(test_inputs), columns = ['predictions'])\n",
    "\n",
    "# Evaluar el modelo para el conjunto de test\n",
    "loss, mae = model.evaluate(test_inputs, test_outputs, verbose=2)\n",
    "print('Loss (MSE): ', loss)\n",
    "print('MAE: ', mae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def RELU(x):\n",
    "    x1=[]\n",
    "    for i in x:\n",
    "        if i<0:\n",
    "            x1.append(0)\n",
    "        else:\n",
    "            x1.append(i)\n",
    "    return x1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 2)\n",
    "plt.plot(x, sigmoid(x), label=\"Sigmoid\")\n",
    "plt.plot(x, tanh(x),  label=\"Tanh\")\n",
    "plt.plot(x, RELU(x),  label=\"ReLu\")\n",
    "plt.axis('tight')\n",
    "plt.xlabel(\"Entrada\")\n",
    "plt.ylabel(\"Salida\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('activations.png', bbox_inches='tight', transparent=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}